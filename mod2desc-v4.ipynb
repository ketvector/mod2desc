{"cells":[{"cell_type":"markdown","metadata":{},"source":["I have chosen the NLP problem to convert pytorch model to natural language descriptions, using synthetic data. \n","\n","The requirements are not precise so i will just note down my assumptions at the top here and also call them out as part of the comments in code:\n","\n","1. What should be the **synthetically created** input and output of the model ?\n","\n","- **Input** : What should be the input to the model ? \n","\n","\tThe doc says - \"(input should be) ... the architecture of a neural network created in PyTorch.This includes detailed information about its layers, configurations, and parameters.\" \n","\n","\tThere are several options which can be considered here:\n","\n","\ta) serialise the model and use the serialised string as input\n","\tb) use the ouput of `__str__()` method of the model\n","\tc) use a library like https://pypi.org/project/torch-summary/ to create it.\n","\n","\tIt will be the toughest for the model to learn from (a) above . (b) & (c) should be comparable.\n","\n","\tFor simplicity i have gone with (b) - using `model.__str__()` for input.\n"," \n","-  **Output**: What should be the output of the model ?\n","\n","\tA couple of options here are: \n","\n","\ta) use a large language model to generate the output (openAI api/self-hosted LLAMA)\n","\tb) write a simple function on my own.\n","\t\t\n","\tFor simplicity, I have gone with (b)\n","\n","2. Which **model** should I use ?\n","\t\n","\tThe doc says a \"seq2seq\" model. The term seq2seq is most often used in the context of a RNN (encoder + decoder) based architecture, with or without attention. Although some people also use it in the context of transformer based architecture, but that is rare.\n","\t\n","\tI have gone with RNN based encoder/decoder arch with attention and adapted my model from here: https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n","    \n","    The choice of seq2seq model means that it typically performs well with input sizes of about 30-50 characters. The sizes I have taken are longer (~220 chars input, ~50 chars output) but the model performs well. Accuracy approaching 100% with 10 epochs of training with 16,000 samples. "]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T06:15:11.150889Z","iopub.status.busy":"2024-07-16T06:15:11.150153Z","iopub.status.idle":"2024-07-16T06:15:14.828354Z","shell.execute_reply":"2024-07-16T06:15:14.827291Z","shell.execute_reply.started":"2024-07-16T06:15:11.150857Z"},"id":"O3Y061k9BEwF","trusted":true},"outputs":[],"source":["\"\"\"\n","All imports at the top\n","\"\"\"\n","\n","from __future__ import unicode_literals, print_function, division\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n","\n","\n","from io import open\n","import unicodedata\n","import re\n","import random\n","from time import time\n","import math\n","import numpy as np\n","import json\n","\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T06:15:14.830644Z","iopub.status.busy":"2024-07-16T06:15:14.830199Z","iopub.status.idle":"2024-07-16T06:15:14.860207Z","shell.execute_reply":"2024-07-16T06:15:14.859266Z","shell.execute_reply.started":"2024-07-16T06:15:14.830615Z"},"id":"6uNx4uYkQV90","trusted":true},"outputs":[{"data":{"text/plain":["'Sequential(\\n  (0): Linear(in_features=2, out_features=10, bias=True)\\n  (1): Linear(in_features=10, out_features=25, bias=True)\\n  (2): Conv1d(25, 3, kernel_size=(1,), stride=(1,))\\n)'"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","A sample of the synthetically generated input I will be using\n","\"\"\"\n","\n","sample = nn.Sequential(nn.Linear(2,10), nn.Linear(10,25), nn.Conv1d(25, 3, 1))\n","sample.__str__()"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T06:15:14.861516Z","iopub.status.busy":"2024-07-16T06:15:14.861222Z","iopub.status.idle":"2024-07-16T06:15:14.873864Z","shell.execute_reply":"2024-07-16T06:15:14.872940Z","shell.execute_reply.started":"2024-07-16T06:15:14.861491Z"},"trusted":true},"outputs":[],"source":["\"\"\"\n","Helper functions to create synthetic data\n","\"\"\"\n","\n","NUM_ITEMS = 20000\n","def find_divisors(n):\n","    # Handle edge case for non-positive numbers\n","    if n <= 0:\n","        return []\n","    \n","    divisors = []\n","    for i in range(1, int(n**0.5) + 1):\n","        if n % i == 0:\n","            divisors.append(i)\n","            if i != n // i:  # Avoid duplicates for perfect squares\n","                divisors.append(n // i)\n","    \n","    return sorted(divisors)\n","\n","\n","def perfect_square_root(n):\n","    if n < 0:\n","        return None\n","    \n","    root = int(math.sqrt(n))\n","    \n","    if root * root == n:\n","        return root\n","    else:\n","        return None\n","\n","\n","\n","def get_dims_helper(dims_left):\n","    divs = find_divisors(dims_left)\n","    for div in divs:\n","        n_2 = dims_left // div\n","        root = perfect_square_root(n_2)\n","        if root is not None:\n","            return div, root, root\n","    return dims_left, 1, 1\n","\n","def get_out_dims_helper(dims_left, h):\n","    divs = find_divisors(dims_left)\n","    for div in divs:\n","        n_2 = dims_left // div\n","        root = perfect_square_root(n_2)\n","        if root is not None:\n","            k = h - root + 1\n","            if k > 0:\n","                return div, k\n","    return dims_left, h\n","        \n","\n","class Reshape(nn.Module):\n","    def __init__(self, size):\n","        super().__init__()\n","        self.size = size\n","    \n","    def forward(self,x):\n","        return x.view(*self.size)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T06:15:14.876310Z","iopub.status.busy":"2024-07-16T06:15:14.875982Z","iopub.status.idle":"2024-07-16T06:15:14.895299Z","shell.execute_reply":"2024-07-16T06:15:14.894360Z","shell.execute_reply.started":"2024-07-16T06:15:14.876279Z"},"trusted":true},"outputs":[],"source":["\"\"\"\n","Generate one synthetic sample.\n","\n","I have made sure to create models that will \"work\". Random sizes for layer dimensions and layer placements\n","would still have been enough for learning the task at hand, but the incompatibility between layers \n","would have meant they would have thrown runtime errors in practice.\n","\n","\"\"\"\n","\n","def get_one_sample():\n","    layer_options = [nn.Linear, nn.Conv2d]\n","    layers = []\n","    sizes = []\n","    num_layers = random.choice(range(0,6))\n","    dim_choices = range(1,10)\n","    curr = None\n","    for layer_idx in range(num_layers):\n","        layer_type = random.choice(layer_options)\n","        if layer_idx == 0:\n","            if layer_type == nn.Linear:\n","                dims = [random.choice(dim_choices) for _ in range(2) ]\n","                layers.append(nn.Linear(*dims))\n","                sizes.append(([\"N\", dims[0]] , [\"N\", dims[1]]))\n","                curr = (layers[-1](torch.ones(32 * dims[0]).view(32, dims[0])))\n","            elif layer_type == nn.Conv2d:\n","                dims = [random.choice(dim_choices) for _ in range(3)]\n","                layers.append(nn.Conv2d(*dims))\n","                sizes.append(([\"N\" , dims[0], \"H\", \"W\"], [\"N\", dims[1], f\"H-{dims[2]}+1\", f\"W-{dims[2]}+1\"]))\n","                curr = (layers[-1](torch.ones(32 * dims[0]* 64 * 64).view(32, dims[0], 64, 64)))\n","        else:\n","                size = curr.size()\n","                if layer_type == nn.Linear:\n","                    if isinstance(layers[-1] , nn.Linear):\n","                        dims = [size[1], random.choice(dim_choices)]\n","                        layers.append(nn.Linear(*dims))\n","                        sizes.append(([\"N\", dims[0]], [\"N\", dims[1]]))\n","                        curr = (layers[-1](curr))\n","                    elif isinstance(layers[-1] , nn.Conv2d):\n","                        layers.append(Reshape([size[0], -1]))\n","                        curr = layers[-1](curr)\n","                        dims = [curr.size()[1], random.choice(dim_choices)]\n","                        layers.append(nn.Linear(*dims))\n","                        sizes.append(([\"N\", dims[0]], [\"N\", dims[1]]))\n","                        curr = (layers[-1](curr))\n","                elif layer_type == nn.Conv2d:\n","                    if isinstance(layers[-1] , nn.Linear):\n","                        dims_left = curr.numel() // size[0]\n","                        c, h, w = get_dims_helper(dims_left) \n","                        layers.append(Reshape([size[0], c, h, w] ))\n","                        curr = layers[-1](curr)\n","                        co, k = get_out_dims_helper(dims_left, h)\n","                        dims = [c, co, k]\n","                        layers.append(nn.Conv2d(*dims))\n","                        sizes.append(([\"N\", c, h, w], [\"N\", co, h-k+1, h-k+1]))\n","                        curr = layers[-1](curr)\n","                    else:\n","                        continue\n","    in_dim = sizes[0][0] if len(sizes) > 0 else None\n","    out_dim = sizes[-1][1] if len(sizes) > 0 else None\n","    return nn.Sequential(*layers), in_dim, out_dim"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T06:15:14.896471Z","iopub.status.busy":"2024-07-16T06:15:14.896231Z","iopub.status.idle":"2024-07-16T06:15:14.906014Z","shell.execute_reply":"2024-07-16T06:15:14.905293Z","shell.execute_reply.started":"2024-07-16T06:15:14.896451Z"},"trusted":true},"outputs":[],"source":["\"\"\"\n","Simple description for a model\n","\"\"\"\n","\n","def get_description(n,i,o):\n","    base =  f\"this model has {n} layers.\"\n","    if i != None:\n","        i = i.__str__().replace(\"'\", \"\")\n","        base = base + f\"the input has shape {i}.\"\n","    if o != None:\n","        o = o.__str__().replace(\"'\", \"\")\n","        base = base + f\"the output has shape {o}\"\n","    return base\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T06:15:14.907361Z","iopub.status.busy":"2024-07-16T06:15:14.907058Z","iopub.status.idle":"2024-07-16T06:15:20.653446Z","shell.execute_reply":"2024-07-16T06:15:20.652489Z","shell.execute_reply.started":"2024-07-16T06:15:14.907329Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[{'model': 'Sequential(\\n  (0): Linear(in_features=3, out_features=7, bias=True)\\n  (1): Reshape()\\n  (2): Conv2d(7, 7, kernel_size=(1, 1), stride=(1, 1))\\n  (3): Reshape()\\n  (4): Linear(in_features=7, out_features=9, bias=True)\\n  (5): Linear(in_features=9, out_features=6, bias=True)\\n)',\n","  'desc': 'this model has 6 layers.the input has shape [N, 3].the output has shape [N, 6]'},\n"," {'model': 'Sequential(\\n  (0): Conv2d(6, 3, kernel_size=(6, 6), stride=(1, 1))\\n)',\n","  'desc': 'this model has 1 layers.the input has shape [N, 6, H, W].the output has shape [N, 3, H-6+1, W-6+1]'},\n"," {'model': 'Sequential(\\n  (0): Linear(in_features=8, out_features=3, bias=True)\\n  (1): Linear(in_features=3, out_features=7, bias=True)\\n  (2): Linear(in_features=7, out_features=1, bias=True)\\n  (3): Reshape()\\n  (4): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1))\\n)',\n","  'desc': 'this model has 5 layers.the input has shape [N, 8].the output has shape [N, 1, 1, 1]'},\n"," {'model': 'Sequential()', 'desc': 'this model has 0 layers.'},\n"," {'model': 'Sequential(\\n  (0): Conv2d(3, 6, kernel_size=(8, 8), stride=(1, 1))\\n  (1): Reshape()\\n  (2): Linear(in_features=19494, out_features=7, bias=True)\\n)',\n","  'desc': 'this model has 3 layers.the input has shape [N, 3, H, W].the output has shape [N, 7]'},\n"," {'model': 'Sequential()', 'desc': 'this model has 0 layers.'},\n"," {'model': 'Sequential(\\n  (0): Linear(in_features=9, out_features=1, bias=True)\\n  (1): Reshape()\\n  (2): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1))\\n)',\n","  'desc': 'this model has 3 layers.the input has shape [N, 9].the output has shape [N, 1, 1, 1]'},\n"," {'model': 'Sequential()', 'desc': 'this model has 0 layers.'},\n"," {'model': 'Sequential(\\n  (0): Conv2d(3, 6, kernel_size=(6, 6), stride=(1, 1))\\n  (1): Reshape()\\n  (2): Linear(in_features=20886, out_features=8, bias=True)\\n  (3): Reshape()\\n  (4): Conv2d(2, 2, kernel_size=(1, 1), stride=(1, 1))\\n)',\n","  'desc': 'this model has 5 layers.the input has shape [N, 3, H, W].the output has shape [N, 2, 2, 2]'},\n"," {'model': 'Sequential(\\n  (0): Conv2d(5, 9, kernel_size=(7, 7), stride=(1, 1))\\n  (1): Reshape()\\n  (2): Linear(in_features=30276, out_features=6, bias=True)\\n)',\n","  'desc': 'this model has 3 layers.the input has shape [N, 5, H, W].the output has shape [N, 6]'}]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","create dataset in memory\n","\"\"\"\n","\n","def create_dataset(num_samples, report_after=4000):\n","    data_pairs = []\n","    for idx in range(num_samples):\n","        m, i ,o = get_one_sample()\n","        n = len(list(m.named_children()))\n","        data_pairs.append({\"model\": m.__str__(), \"desc\": get_description(n, i, o)})\n","        if idx % report_after == 0 and idx >= report_after:\n","            print(f\"wrote {idx} items to disk ....\")\n","    return data_pairs\n","\n","dp = create_dataset(2000)\n","dp[:10]"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T06:15:20.654793Z","iopub.status.busy":"2024-07-16T06:15:20.654495Z","iopub.status.idle":"2024-07-16T06:16:12.130155Z","shell.execute_reply":"2024-07-16T06:16:12.129162Z","shell.execute_reply.started":"2024-07-16T06:15:20.654767Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["wrote 4000 items to disk ....\n","wrote 8000 items to disk ....\n","wrote 12000 items to disk ....\n","wrote 16000 items to disk ....\n","created a synthetic dataset with number of items: 20000 and saved to disk\n","sample dataset entry:\n"," input: Sequential(\n","  (0): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1))\n",")\n"," output: this model has 1 layers.the input has shape [N, 8, H, W].the output has shape [N, 8, H-1+1, W-1+1]\n"]}],"source":["\"\"\"\n","write dataset to disk\n","\"\"\"\n","\n","def write_dataset():\n","  data = create_dataset(NUM_ITEMS)\n","  json_data = json.dumps(data)\n","  json_data\n","\n","  with open(\"simple_data.json\", \"w\") as f:\n","    f.write(json_data)\n","  print(f\"created a synthetic dataset with number of items: {len(data)} and saved to disk\")\n","  print(f\"sample dataset entry:\\n input: {data[0]['model']}\\n output: {data[0]['desc']}\")\n","\n","write_dataset()\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T06:16:12.131936Z","iopub.status.busy":"2024-07-16T06:16:12.131570Z","iopub.status.idle":"2024-07-16T06:16:12.140966Z","shell.execute_reply":"2024-07-16T06:16:12.139921Z","shell.execute_reply.started":"2024-07-16T06:16:12.131903Z"},"id":"S_npuYpdAxzp","trusted":true},"outputs":[],"source":["\"\"\"\n","class to create a Vocabulary\n","\"\"\"\n","\n","SOS_token = 0\n","EOS_token = 1\n","PADDING_token = 2\n","\n","class Lang:\n","    def __init__(self, name):\n","        self.name = name\n","        self.word2index = {}\n","        self.word2count = {}\n","        self.index2word = {0: \"SOS\", 1: \"EOS\", 2: \"PADDING\"}\n","        self.n_words = 2  # Count SOS and EOS\n","\n","    def addSentence(self, sentence):\n","        for word in sentence.split(' '):\n","            if word.isdigit():\n","              self.addInteger(word)\n","            else:\n","              self.addWord(word)\n","\n","    def addInteger(self, word):\n","      for digit in word:\n","        self.addWord(word)\n","\n","    def addWord(self, word):\n","        if word not in self.word2index:\n","            self.word2index[word] = self.n_words\n","            self.word2count[word] = 1\n","            self.index2word[self.n_words] = word\n","            self.n_words += 1\n","        else:\n","            self.word2count[word] += 1"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"execution":{"iopub.execute_input":"2024-07-16T06:16:12.142349Z","iopub.status.busy":"2024-07-16T06:16:12.142029Z","iopub.status.idle":"2024-07-16T06:16:12.153277Z","shell.execute_reply":"2024-07-16T06:16:12.152269Z","shell.execute_reply.started":"2024-07-16T06:16:12.142325Z"},"id":"Ev-rFDeNA3SZ","outputId":"b3c4298e-477f-4dc5-f421-f40065ed2bea","trusted":true},"outputs":[{"data":{"text/plain":["'sequential ( \\n   ( 0 ) : conv1d ( 7 ,  1 ,  kernel_size =  ( 3 ,  )  ,  stride =  ( 1 ,  )  ) \\n   ( 1 ) : linear ( in_features = 8 ,  out_features = 1 ,  bias = true ) \\n )'"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","data preprocessing helper: normalise input and output\n","\"\"\"\n","\n","def normalizeString(s):\n","    s = re.sub(r\"([.!?()=,])\", r\" \\1 \", s)\n","#     s = re.sub(r\"([():,=\\n])\", r\"\", s)\n","#     s = re.sub(r\"  \", r\" \", s)\n","    return s.lower().strip()\n","\n","x = normalizeString(\"Sequential(\\n  (0): Conv1d(7, 1, kernel_size=(3,), stride=(1,))\\n  (1): Linear(in_features=8, out_features=1, bias=True)\\n)\")\n","x"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-07-16T06:16:12.157362Z","iopub.status.busy":"2024-07-16T06:16:12.157048Z","iopub.status.idle":"2024-07-16T06:16:12.163050Z","shell.execute_reply":"2024-07-16T06:16:12.162132Z","shell.execute_reply.started":"2024-07-16T06:16:12.157339Z"},"id":"-KG6ufIz97EW","outputId":"eb7c24d8-e52f-43e8-b67e-dc177f244584","trusted":true},"outputs":[],"source":["\"\"\"\n","Helper function to read data from disk and create vocabularies\n","\"\"\"\n","\n","def load_data():\n","    print(\"Reading lines...\")\n","\n","    # Read the file and split into lines\n","    lines = []\n","    with open('simple_data.json') as f:\n","      lines = json.load(f)\n","\n","    pairs = [[normalizeString(item[\"model\"]), normalizeString(item[\"desc\"])] for item in lines]\n","    input_lang = Lang(\"model\")\n","    output_lang = Lang(\"desc\")\n","\n","    return input_lang, output_lang, pairs"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-07-16T06:16:12.164465Z","iopub.status.busy":"2024-07-16T06:16:12.164177Z","iopub.status.idle":"2024-07-16T06:16:14.710344Z","shell.execute_reply":"2024-07-16T06:16:14.709297Z","shell.execute_reply.started":"2024-07-16T06:16:12.164443Z"},"id":"dNrT_fMmAp03","outputId":"e44deeb9-769a-4c4f-8bf8-d0dd1635c442","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading lines...\n","Read 20000 sentence pairs\n","Counting words...\n","Counted words:\n","model 110\n","desc 53\n","A random input/output pair : ['sequential ( \\n   ( 0 ) : linear ( in_features = 4 ,  out_features = 6 ,  bias = true ) \\n   ( 1 ) : linear ( in_features = 6 ,  out_features = 8 ,  bias = true ) \\n   ( 2 ) : reshape (  ) \\n   ( 3 ) : conv2d ( 2 ,  2 ,  kernel_size =  ( 1 ,  1 )  ,  stride =  ( 1 ,  1 )  ) \\n )', 'this model has 4 layers . the input has shape [n ,  4] . the output has shape [n ,  2 ,  2 ,  2]']\n"]}],"source":["\"\"\"\n","read data from disk and create vocabs\n","\"\"\"\n","\n","def prepareData():\n","    input_lang, output_lang, pairs = load_data()\n","    print(\"Read %s sentence pairs\" % len(pairs))\n","    print(\"Counting words...\")\n","    for pair in pairs:\n","        input_lang.addSentence(pair[0])\n","        output_lang.addSentence(pair[1])\n","    print(\"Counted words:\")\n","    print(input_lang.name, input_lang.n_words)\n","    print(output_lang.name, output_lang.n_words)\n","    return input_lang, output_lang, pairs\n","\n","input_lang, output_lang, pairs = prepareData()\n","random_pair = random.choice(pairs)\n","print(f\"A random input/output pair : {random_pair}\")"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-07-16T06:16:14.712555Z","iopub.status.busy":"2024-07-16T06:16:14.712160Z","iopub.status.idle":"2024-07-16T06:16:14.720075Z","shell.execute_reply":"2024-07-16T06:16:14.719121Z","shell.execute_reply.started":"2024-07-16T06:16:14.712520Z"},"id":"Nsw9v84sDUjk","outputId":"fb77dc06-828d-4d8e-f2ab-108eb873cfd8","trusted":true},"outputs":[],"source":["\"\"\"\n","Helper functions\n","\"\"\"\n","\n","def indexesFromSentence(lang, sentence):\n","    return [lang.word2index[word] for word in sentence.split(' ')]\n","\n","def tensorFromSentence(lang, sentence):\n","    indexes = indexesFromSentence(lang, sentence)\n","    indexes.append(EOS_token)\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n","\n","def tensorsFromPair(pair):\n","    input_tensor = tensorFromSentence(input_lang, pair[0])\n","    target_tensor = tensorFromSentence(output_lang, pair[1])\n","    return (input_tensor, target_tensor)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-07-16T06:16:14.721750Z","iopub.status.busy":"2024-07-16T06:16:14.721437Z","iopub.status.idle":"2024-07-16T06:16:15.018531Z","shell.execute_reply":"2024-07-16T06:16:15.017487Z","shell.execute_reply.started":"2024-07-16T06:16:14.721713Z"},"id":"MKKuzYUkK2Ez","outputId":"6dce8c59-e7fd-40ae-e969-532533b2ff82","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["longest input sentence : 208.\n","longest output sentence 35.\n"]}],"source":["\"\"\"\n","Empirically test max length of input and output\n","\"\"\"\n","\n","def maxLength(l,lang):\n","  m = len(indexesFromSentence(lang, l[0]))\n","  for s in l:\n","    if len(indexesFromSentence(lang, s)) > m:\n","      m = len(indexesFromSentence(lang,s))\n","  return m\n","\n","l1s = [item[0] for item in pairs]\n","l2s = [item[1] for item in pairs]\n","m1 = maxLength(l1s, input_lang)\n","m2 = maxLength(l2s, output_lang)\n","print(f\"longest input sentence : {m1}.\\nlongest output sentence {m2}.\")"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T06:16:15.020271Z","iopub.status.busy":"2024-07-16T06:16:15.019928Z","iopub.status.idle":"2024-07-16T06:16:15.024187Z","shell.execute_reply":"2024-07-16T06:16:15.023342Z","shell.execute_reply.started":"2024-07-16T06:16:15.020245Z"},"id":"84Swpy-vPf1z","trusted":true},"outputs":[],"source":["\"\"\"\n","set input and output max length\n","\"\"\"\n","\n","MAX_LENGTH_INPUT = 220\n","MAX_LENGTH_OUTPUT = 50"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T06:16:15.025916Z","iopub.status.busy":"2024-07-16T06:16:15.025605Z","iopub.status.idle":"2024-07-16T06:16:15.038330Z","shell.execute_reply":"2024-07-16T06:16:15.037455Z","shell.execute_reply.started":"2024-07-16T06:16:15.025891Z"},"id":"gnSMBHl1JAwa","trusted":true},"outputs":[],"source":["\"\"\"\n","Create a dataloader\n","\"\"\"\n","def helper(inputs, targets, l, r):\n","    input_ids = inputs[l :  r, :]\n","    target_ids = targets[l: r, :]\n","    data = TensorDataset(torch.LongTensor(input_ids).to(device),\n","                               torch.LongTensor(target_ids).to(device))\n","    sampler = RandomSampler(data)\n","    dataloader = DataLoader(data, sampler=sampler, batch_size=batch_size)\n","    return dataloader\n","    \n","def get_dataloader(batch_size, test_split = 0.2):\n","    input_lang, output_lang, pairs = prepareData()\n","\n","    n = len(pairs)\n","    input_ids = np.full((n, MAX_LENGTH_INPUT), PADDING_token ,dtype=np.int32)\n","    target_ids = np.full((n, MAX_LENGTH_OUTPUT),  PADDING_token,  dtype=np.int32)\n","\n","    for idx, (inp, tgt) in enumerate(pairs):\n","        inp_ids = indexesFromSentence(input_lang, inp)\n","        tgt_ids =  indexesFromSentence(output_lang, tgt)\n","        inp_ids.append(EOS_token)\n","        tgt_ids.append(EOS_token)\n","        input_ids[idx, :len(inp_ids)] = inp_ids\n","        target_ids[idx, :len(tgt_ids)] = tgt_ids\n","    \n","    test_size = int(test_split * n)\n","    train_size = n - test_size\n","    \n","    print(f\"train size: {train_size}. test size: {test_size}\")\n","    train_dataloader = helper(input_ids, target_ids, 0, train_size)\n","    test_dataloader = helper(input_ids, target_ids, train_size, n)\n","    \n","    \n","    return input_lang, output_lang, train_dataloader, test_dataloader"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T06:16:15.040036Z","iopub.status.busy":"2024-07-16T06:16:15.039761Z","iopub.status.idle":"2024-07-16T06:16:15.047345Z","shell.execute_reply":"2024-07-16T06:16:15.046519Z","shell.execute_reply.started":"2024-07-16T06:16:15.040014Z"},"id":"bS6VvX5LRkSn","trusted":true},"outputs":[],"source":["\"\"\"\n","Encoder RNN\n","\"\"\"\n","class EncoderRNN(nn.Module):\n","    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n","        super(EncoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","\n","        self.embedding = nn.Embedding(input_size, hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n","        self.dropout = nn.Dropout(dropout_p)\n","\n","    def forward(self, input):\n","        embedded = self.dropout(self.embedding(input))\n","        output, hidden = self.gru(embedded)\n","        return output, hidden"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T06:16:15.048909Z","iopub.status.busy":"2024-07-16T06:16:15.048576Z","iopub.status.idle":"2024-07-16T06:16:15.073108Z","shell.execute_reply":"2024-07-16T06:16:15.072364Z","shell.execute_reply.started":"2024-07-16T06:16:15.048875Z"},"id":"7l_R4_NGRqex","trusted":true},"outputs":[],"source":["\"\"\"\n","Decoder RNN. The code is written so that we have the option of using teacher forcing at runtime.\n","In practice, teacher forcing works very well.\n","\"\"\"\n","\n","class DecoderRNN(nn.Module):\n","    def __init__(self, hidden_size, output_size):\n","        super(DecoderRNN, self).__init__()\n","        self.embedding = nn.Embedding(output_size, hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n","        self.out = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n","        batch_size = encoder_outputs.size(0)\n","        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n","        decoder_hidden = encoder_hidden\n","        decoder_outputs = []\n","\n","        for i in range(MAX_LENGTH_OUTPUT):\n","            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n","            decoder_outputs.append(decoder_output)\n","\n","            if target_tensor is not None:\n","                # Teacher forcing: Feed the target as the next input\n","                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n","            else:\n","                # Without teacher forcing: use its own predictions as the next input\n","                _, topi = decoder_output.topk(1)\n","                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n","\n","        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n","        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n","        return decoder_outputs, decoder_hidden, None # We return `None` for consistency in the training loop\n","\n","    def forward_step(self, input, hidden):\n","        output = self.embedding(input)\n","        output = F.relu(output)\n","        output, hidden = self.gru(output, hidden)\n","        output = self.out(output)\n","        return output, hidden\n","\n","  \n","    \n","class BahdanauAttention(nn.Module):\n","    def __init__(self, hidden_size):\n","        super(BahdanauAttention, self).__init__()\n","        self.Wa = nn.Linear(hidden_size, hidden_size)\n","        self.Ua = nn.Linear(hidden_size, hidden_size)\n","        self.Va = nn.Linear(hidden_size, 1)\n","\n","    def forward(self, query, keys):\n","        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n","        scores = scores.squeeze(2).unsqueeze(1)\n","\n","        weights = F.softmax(scores, dim=-1)\n","        context = torch.bmm(weights, keys)\n","\n","        return context, weights\n","\n","\"\"\"\n","Decoder RNN with attention\n","\"\"\"      \n","class AttnDecoderRNN(nn.Module):\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n","        super(AttnDecoderRNN, self).__init__()\n","        self.embedding = nn.Embedding(output_size, hidden_size)\n","        self.attention = BahdanauAttention(hidden_size)\n","        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n","        self.out = nn.Linear(hidden_size, output_size)\n","        self.dropout = nn.Dropout(dropout_p)\n","\n","    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n","        batch_size = encoder_outputs.size(0)\n","        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n","        decoder_hidden = encoder_hidden\n","        decoder_outputs = []\n","        attentions = []\n","\n","        for i in range(MAX_LENGTH_OUTPUT):\n","            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n","                decoder_input, decoder_hidden, encoder_outputs\n","            )\n","            decoder_outputs.append(decoder_output)\n","            attentions.append(attn_weights)\n","\n","            if target_tensor is not None:\n","                # Teacher forcing: Feed the target as the next input\n","                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n","            else:\n","                # Without teacher forcing: use its own predictions as the next input\n","                _, topi = decoder_output.topk(1)\n","                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n","\n","        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n","        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n","        attentions = torch.cat(attentions, dim=1)\n","\n","        return decoder_outputs, decoder_hidden, attentions\n","\n","\n","    def forward_step(self, input, hidden, encoder_outputs):\n","        embedded =  self.dropout(self.embedding(input))\n","\n","        query = hidden.permute(1, 0, 2)\n","        context, attn_weights = self.attention(query, encoder_outputs)\n","        input_gru = torch.cat((embedded, context), dim=2)\n","\n","        output, hidden = self.gru(input_gru, hidden)\n","        output = self.out(output)\n","\n","        return output, hidden, attn_weights\n","\n"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T06:16:15.074444Z","iopub.status.busy":"2024-07-16T06:16:15.074152Z","iopub.status.idle":"2024-07-16T06:16:15.084020Z","shell.execute_reply":"2024-07-16T06:16:15.083280Z","shell.execute_reply.started":"2024-07-16T06:16:15.074419Z"},"trusted":true},"outputs":[],"source":["\"\"\"\n","train one epoch\n","\"\"\"\n","\n","def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n","          decoder_optimizer, criterion, epoch, print_every = 100 ):\n","\n","    total_loss = 0\n","    t = time()\n","    idx = 0\n","    for data in dataloader:\n","\n","        input_tensor, target_tensor = data\n","\n","        encoder_optimizer.zero_grad()\n","        decoder_optimizer.zero_grad()\n","\n","        encoder_outputs, encoder_hidden = encoder(input_tensor)\n","        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n","\n","        loss = criterion(\n","            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n","            target_tensor.view(-1)\n","        )\n","        loss.backward()\n","\n","        encoder_optimizer.step()\n","        decoder_optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","        if(idx % print_every == 0 and idx != 0):\n","          print(f\"batches : {idx-print_every} - {idx}  of epoch {epoch} took time: {time() - t}.\")\n","          t = time()\n","        idx = idx+1\n","\n","    return total_loss / len(dataloader)"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T06:16:15.085506Z","iopub.status.busy":"2024-07-16T06:16:15.085156Z","iopub.status.idle":"2024-07-16T06:16:15.092164Z","shell.execute_reply":"2024-07-16T06:16:15.091345Z","shell.execute_reply.started":"2024-07-16T06:16:15.085472Z"},"id":"U1RUVe44RF59","trusted":true},"outputs":[],"source":["\"\"\"\n","helper functions\n","\"\"\"\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","def timeSince(since, percent):\n","    now = time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T06:46:35.019737Z","iopub.status.busy":"2024-07-16T06:46:35.019329Z","iopub.status.idle":"2024-07-16T06:46:35.029447Z","shell.execute_reply":"2024-07-16T06:46:35.028558Z","shell.execute_reply.started":"2024-07-16T06:46:35.019709Z"},"id":"6DYgHnE1RMng","trusted":true},"outputs":[],"source":["\"\"\"\n","define function for complete training\n","\"\"\"\n","\n","def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n","               print_every=100, plot_every=100, save_file_suffix = \"\"):\n","    start = time()\n","    plot_losses = []\n","    print_loss_total = 0  # Reset every print_every\n","    plot_loss_total = 0  # Reset every plot_every\n","\n","    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n","    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n","    criterion = nn.NLLLoss()\n","\n","    for epoch in range(1, n_epochs + 1):\n","        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, epoch = epoch)\n","        print_loss_total += loss\n","        plot_loss_total += loss\n","\n","        if epoch % print_every == 0:\n","            torch.save(encoder.state_dict(), f\"./encoder-{save_file_suffix}-{epoch}\")\n","            torch.save(decoder.state_dict(), f\"./decoder-{save_file_suffix}-{epoch}\")\n","            print_loss_avg = print_loss_total / print_every\n","            print_loss_total = 0\n","            print('EPOCH %d done. %s (%d %d%%) avearage loss: %.4f' % (epoch, timeSince(start, epoch / n_epochs),\n","                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n","\n","        if epoch % plot_every == 0:\n","            plot_loss_avg = plot_loss_total / plot_every\n","            plot_losses.append(plot_loss_avg)\n","            plot_loss_total = 0\n"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"execution":{"iopub.execute_input":"2024-07-16T06:46:35.621972Z","iopub.status.busy":"2024-07-16T06:46:35.621650Z","iopub.status.idle":"2024-07-16T06:53:36.724476Z","shell.execute_reply":"2024-07-16T06:53:36.723543Z","shell.execute_reply.started":"2024-07-16T06:46:35.621947Z"},"id":"EKEBQLTSRgil","outputId":"31c6466b-f844-4fe9-a24f-5c605f38f7ca","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading lines...\n","Read 20000 sentence pairs\n","Counting words...\n","Counted words:\n","model 110\n","desc 53\n","train size: 16000. test size: 4000\n","batches : 0 - 100  of epoch 1 took time: 8.473941802978516.\n","batches : 100 - 200  of epoch 1 took time: 8.34061861038208.\n","batches : 200 - 300  of epoch 1 took time: 8.379926919937134.\n","batches : 300 - 400  of epoch 1 took time: 8.469292402267456.\n","EPOCH 1 done. 0m 42s (- 6m 18s) (1 10%) avearage loss: 0.2971\n","batches : 0 - 100  of epoch 2 took time: 8.423267841339111.\n","batches : 100 - 200  of epoch 2 took time: 8.37239670753479.\n","batches : 200 - 300  of epoch 2 took time: 8.450244903564453.\n","batches : 300 - 400  of epoch 2 took time: 8.290489196777344.\n","EPOCH 2 done. 1m 23s (- 5m 35s) (2 20%) avearage loss: 0.0562\n","batches : 0 - 100  of epoch 3 took time: 8.436162233352661.\n","batches : 100 - 200  of epoch 3 took time: 8.402474164962769.\n","batches : 200 - 300  of epoch 3 took time: 8.35907769203186.\n","batches : 300 - 400  of epoch 3 took time: 8.267791748046875.\n","EPOCH 3 done. 2m 5s (- 4m 53s) (3 30%) avearage loss: 0.0115\n","batches : 0 - 100  of epoch 4 took time: 8.50065541267395.\n","batches : 100 - 200  of epoch 4 took time: 8.351497888565063.\n","batches : 200 - 300  of epoch 4 took time: 8.286925792694092.\n","batches : 300 - 400  of epoch 4 took time: 8.320127248764038.\n","EPOCH 4 done. 2m 47s (- 4m 11s) (4 40%) avearage loss: 0.0078\n","batches : 0 - 100  of epoch 5 took time: 8.401658535003662.\n","batches : 100 - 200  of epoch 5 took time: 8.30204153060913.\n","batches : 200 - 300  of epoch 5 took time: 8.372209310531616.\n","batches : 300 - 400  of epoch 5 took time: 8.464751958847046.\n","EPOCH 5 done. 3m 29s (- 3m 29s) (5 50%) avearage loss: 0.0031\n","batches : 0 - 100  of epoch 6 took time: 8.402701377868652.\n","batches : 100 - 200  of epoch 6 took time: 8.497881174087524.\n","batches : 200 - 300  of epoch 6 took time: 8.32158350944519.\n","batches : 300 - 400  of epoch 6 took time: 8.274828910827637.\n","EPOCH 6 done. 4m 11s (- 2m 47s) (6 60%) avearage loss: 0.0008\n","batches : 0 - 100  of epoch 7 took time: 8.475096940994263.\n","batches : 100 - 200  of epoch 7 took time: 8.233327865600586.\n","batches : 200 - 300  of epoch 7 took time: 8.347994565963745.\n","batches : 300 - 400  of epoch 7 took time: 8.330747842788696.\n","EPOCH 7 done. 4m 52s (- 2m 5s) (7 70%) avearage loss: 0.0011\n","batches : 0 - 100  of epoch 8 took time: 8.387349128723145.\n","batches : 100 - 200  of epoch 8 took time: 8.341842412948608.\n","batches : 200 - 300  of epoch 8 took time: 8.278261661529541.\n","batches : 300 - 400  of epoch 8 took time: 8.402803897857666.\n","EPOCH 8 done. 5m 34s (- 1m 23s) (8 80%) avearage loss: 0.0002\n","batches : 0 - 100  of epoch 9 took time: 8.476083755493164.\n","batches : 100 - 200  of epoch 9 took time: 8.560318231582642.\n","batches : 200 - 300  of epoch 9 took time: 8.321957349777222.\n","batches : 300 - 400  of epoch 9 took time: 8.331254243850708.\n","EPOCH 9 done. 6m 16s (- 0m 41s) (9 90%) avearage loss: 0.0001\n","batches : 0 - 100  of epoch 10 took time: 8.526540756225586.\n","batches : 100 - 200  of epoch 10 took time: 8.293506383895874.\n","batches : 200 - 300  of epoch 10 took time: 8.320956945419312.\n","batches : 300 - 400  of epoch 10 took time: 8.299473285675049.\n","EPOCH 10 done. 6m 58s (- 0m 0s) (10 100%) avearage loss: 0.0001\n"]}],"source":["\"\"\"\n","actual training\n","\"\"\"\n","\n","\n","hidden_size = 128\n","batch_size = 32\n","\n","input_lang, output_lang, train_dataloader, test_loader = get_dataloader(batch_size)\n","\n","encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n","decoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n","\n","train(train_dataloader, encoder, decoder, 10 , print_every=1, plot_every=1, save_file_suffix=\"trial\")"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T06:53:45.976301Z","iopub.status.busy":"2024-07-16T06:53:45.975618Z","iopub.status.idle":"2024-07-16T06:53:45.983067Z","shell.execute_reply":"2024-07-16T06:53:45.982141Z","shell.execute_reply.started":"2024-07-16T06:53:45.976268Z"},"trusted":true},"outputs":[],"source":["\"\"\"\n","helpers to load trained models\n","\"\"\"\n","\n","import os.path\n","\n","\n","def load_model(model, path):\n","    model.load_state_dict(torch.load(path))\n","    model.eval()\n","    return model\n","\n","def get_trained_models(save_path_encoder, save_path_decoder):\n","    if os.path.isfile(save_path_encoder) and os.path.isfile(save_path_decoder):\n","        e = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n","        d = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n","        e = load_model(e, save_path_encoder)\n","        d = load_model(d, save_path_decoder)\n","        return e, d\n","    print(f\"pre trained weigths do not exist at given path\")\n","    return None, None"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T06:53:46.824334Z","iopub.status.busy":"2024-07-16T06:53:46.823959Z","iopub.status.idle":"2024-07-16T06:53:46.832200Z","shell.execute_reply":"2024-07-16T06:53:46.831269Z","shell.execute_reply.started":"2024-07-16T06:53:46.824305Z"},"trusted":true},"outputs":[],"source":["\"\"\"\n","helper to evaluate a single translation\n","\"\"\"\n","\n","def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n","    with torch.no_grad():\n","        \n","        input_ids = np.full((1, MAX_LENGTH_INPUT),  PADDING_token,  dtype=np.int32)\n","        inputs = indexesFromSentence(input_lang, sentence)\n","        inputs.append(EOS_token)\n","        input_ids[0, : len(inputs)] = inputs\n","        \n","        input_tensor = torch.tensor(input_ids).to(device)\n","\n","        encoder_outputs, encoder_hidden = encoder(input_tensor)\n","        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n","\n","        _, topi = decoder_outputs.topk(1)\n","        decoded_ids = topi.squeeze()\n","\n","        decoded_words = []\n","        for idx in decoded_ids:\n","            if idx.item() == EOS_token:\n","                decoded_words.append('<EOS>')\n","                break\n","            decoded_words.append(output_lang.index2word[idx.item()])\n","    return decoded_words, decoder_attn"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T06:53:47.921828Z","iopub.status.busy":"2024-07-16T06:53:47.920922Z","iopub.status.idle":"2024-07-16T06:53:47.927544Z","shell.execute_reply":"2024-07-16T06:53:47.926571Z","shell.execute_reply.started":"2024-07-16T06:53:47.921794Z"},"id":"dic1NJ2rRfGX","trusted":true},"outputs":[],"source":["\"\"\"\n","get a taste of the translations\n","\"\"\"\n","\n","def evaluateRandomly(encoder, decoder, n=10):\n","    for i in range(n):\n","        pair = random.choice(pairs)\n","        print('>', pair[0])\n","        print('=', pair[1])\n","        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n","        output_sentence = ' '.join(output_words)\n","        print('<', output_sentence)\n","        print('')"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T06:53:53.119379Z","iopub.status.busy":"2024-07-16T06:53:53.118985Z","iopub.status.idle":"2024-07-16T06:53:53.412656Z","shell.execute_reply":"2024-07-16T06:53:53.411719Z","shell.execute_reply.started":"2024-07-16T06:53:53.119350Z"},"id":"cGxsoyXTWZSb","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["KEY:\n","> INPUT\n","= TARGET\n","< MACHINE TRANSLATION\n","\n","----------------\n","\n","> sequential ( \n","   ( 0 ) : linear ( in_features = 1 ,  out_features = 8 ,  bias = true ) \n","   ( 1 ) : linear ( in_features = 8 ,  out_features = 7 ,  bias = true ) \n"," )\n","= this model has 2 layers . the input has shape [n ,  1] . the output has shape [n ,  7]\n","< this model has 2 layers . the input has shape [n ,  1] . the output has shape [n ,  7] <EOS>\n","\n","> sequential ( \n","   ( 0 ) : conv2d ( 8 ,  2 ,  kernel_size =  ( 2 ,  2 )  ,  stride =  ( 1 ,  1 )  ) \n","   ( 1 ) : reshape (  ) \n","   ( 2 ) : linear ( in_features = 7938 ,  out_features = 3 ,  bias = true ) \n"," )\n","= this model has 3 layers . the input has shape [n ,  8 ,  h ,  w] . the output has shape [n ,  3]\n","< this model has 3 layers . the input has shape [n ,  8 ,  h ,  w] . the output has shape [n ,  3] <EOS>\n","\n","> sequential ( \n","   ( 0 ) : conv2d ( 6 ,  5 ,  kernel_size =  ( 4 ,  4 )  ,  stride =  ( 1 ,  1 )  ) \n"," )\n","= this model has 1 layers . the input has shape [n ,  6 ,  h ,  w] . the output has shape [n ,  5 ,  h-4+1 ,  w-4+1]\n","< this model has 1 layers . the input has shape [n ,  6 ,  h ,  w] . the output has shape [n ,  5 ,  h-4+1 ,  w-4+1] <EOS>\n","\n","> sequential ( \n","   ( 0 ) : linear ( in_features = 3 ,  out_features = 2 ,  bias = true ) \n","   ( 1 ) : reshape (  ) \n","   ( 2 ) : conv2d ( 2 ,  2 ,  kernel_size =  ( 1 ,  1 )  ,  stride =  ( 1 ,  1 )  ) \n","   ( 3 ) : reshape (  ) \n","   ( 4 ) : linear ( in_features = 2 ,  out_features = 8 ,  bias = true ) \n","   ( 5 ) : reshape (  ) \n","   ( 6 ) : conv2d ( 2 ,  2 ,  kernel_size =  ( 1 ,  1 )  ,  stride =  ( 1 ,  1 )  ) \n"," )\n","= this model has 7 layers . the input has shape [n ,  3] . the output has shape [n ,  2 ,  2 ,  2]\n","< this model has 7 layers . the input has shape [n ,  3] . the output has shape [n ,  2 ,  2 ,  2] <EOS>\n","\n","> sequential ( \n","   ( 0 ) : linear ( in_features = 4 ,  out_features = 9 ,  bias = true ) \n"," )\n","= this model has 1 layers . the input has shape [n ,  4] . the output has shape [n ,  9]\n","< this model has 1 layers . the input has shape [n ,  4] . the output has shape [n ,  9] <EOS>\n","\n","> sequential ( \n","   ( 0 ) : conv2d ( 6 ,  9 ,  kernel_size =  ( 8 ,  8 )  ,  stride =  ( 1 ,  1 )  ) \n","   ( 1 ) : reshape (  ) \n","   ( 2 ) : linear ( in_features = 29241 ,  out_features = 3 ,  bias = true ) \n","   ( 3 ) : reshape (  ) \n","   ( 4 ) : conv2d ( 3 ,  3 ,  kernel_size =  ( 1 ,  1 )  ,  stride =  ( 1 ,  1 )  ) \n"," )\n","= this model has 5 layers . the input has shape [n ,  6 ,  h ,  w] . the output has shape [n ,  3 ,  1 ,  1]\n","< this model has 5 layers . the input has shape [n ,  6 ,  h ,  w] . the output has shape [n ,  3 ,  1 ,  1] <EOS>\n","\n","> sequential ( \n","   ( 0 ) : linear ( in_features = 7 ,  out_features = 4 ,  bias = true ) \n","   ( 1 ) : reshape (  ) \n","   ( 2 ) : conv2d ( 1 ,  1 ,  kernel_size =  ( 1 ,  1 )  ,  stride =  ( 1 ,  1 )  ) \n","   ( 3 ) : reshape (  ) \n","   ( 4 ) : linear ( in_features = 4 ,  out_features = 7 ,  bias = true ) \n","   ( 5 ) : linear ( in_features = 7 ,  out_features = 3 ,  bias = true ) \n"," )\n","= this model has 6 layers . the input has shape [n ,  7] . the output has shape [n ,  3]\n","< this model has 6 layers . the input has shape [n ,  7] . the output has shape [n ,  3] <EOS>\n","\n","> sequential ( \n","   ( 0 ) : linear ( in_features = 8 ,  out_features = 2 ,  bias = true ) \n","   ( 1 ) : linear ( in_features = 2 ,  out_features = 3 ,  bias = true ) \n","   ( 2 ) : linear ( in_features = 3 ,  out_features = 1 ,  bias = true ) \n","   ( 3 ) : reshape (  ) \n","   ( 4 ) : conv2d ( 1 ,  1 ,  kernel_size =  ( 1 ,  1 )  ,  stride =  ( 1 ,  1 )  ) \n","   ( 5 ) : reshape (  ) \n","   ( 6 ) : linear ( in_features = 1 ,  out_features = 7 ,  bias = true ) \n"," )\n","= this model has 7 layers . the input has shape [n ,  8] . the output has shape [n ,  7]\n","< this model has 7 layers . the input has shape [n ,  8] . the output has shape [n ,  7] <EOS>\n","\n","> sequential ( \n","   ( 0 ) : linear ( in_features = 4 ,  out_features = 3 ,  bias = true ) \n","   ( 1 ) : linear ( in_features = 3 ,  out_features = 5 ,  bias = true ) \n","   ( 2 ) : linear ( in_features = 5 ,  out_features = 1 ,  bias = true ) \n","   ( 3 ) : linear ( in_features = 1 ,  out_features = 4 ,  bias = true ) \n","   ( 4 ) : linear ( in_features = 4 ,  out_features = 6 ,  bias = true ) \n"," )\n","= this model has 5 layers . the input has shape [n ,  4] . the output has shape [n ,  6]\n","< this model has 5 layers . the input has shape [n ,  4] . the output has shape [n ,  6] <EOS>\n","\n","> sequential ( \n","   ( 0 ) : conv2d ( 2 ,  2 ,  kernel_size =  ( 8 ,  8 )  ,  stride =  ( 1 ,  1 )  ) \n","   ( 1 ) : reshape (  ) \n","   ( 2 ) : linear ( in_features = 6498 ,  out_features = 9 ,  bias = true ) \n"," )\n","= this model has 3 layers . the input has shape [n ,  2 ,  h ,  w] . the output has shape [n ,  9]\n","< this model has 3 layers . the input has shape [n ,  2 ,  h ,  w] . the output has shape [n ,  9] <EOS>\n","\n"]}],"source":["def print_key():\n","    print(f\"KEY:\\n> INPUT\\n= TARGET\\n< MACHINE TRANSLATION\\n\\n----------------\\n\")\n","\n","encoder.eval()\n","decoder.eval()\n","\n","print_key()\n","# e, d = get_trained_models(\"encoder-trial-10\", \"decoder-trial-10\")\n","# evaluateRandomly(e, d)\n","# UNCOMMENT TO TEST WITH TRAINED MODEL DIRECTLY\n","evaluateRandomly(encoder, decoder)"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T06:54:00.887224Z","iopub.status.busy":"2024-07-16T06:54:00.886498Z","iopub.status.idle":"2024-07-16T06:54:00.925533Z","shell.execute_reply":"2024-07-16T06:54:00.924607Z","shell.execute_reply.started":"2024-07-16T06:54:00.887187Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["predicted : tensor([[ 2,  3,  4, 24,  6,  7,  8,  9,  4, 10, 11, 12, 13, 14, 12, 13, 15, 12,\n","         13, 16,  7,  8, 17,  4, 10, 11, 12, 13, 31, 12, 13, 51, 12, 13, 52,  1,\n","          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2]],\n","       device='cuda:0')\n"]}],"source":["\"\"\"\n","helper to get tensor translation of a single input. will be used to calculate metrics \n","\"\"\"\n","\n","def get_prediction(source, encoder, decoder, input_lang):\n","    with torch.no_grad():\n","        input_tensor = tensorFromSentence(input_lang, source)\n","\n","        encoder_outputs, encoder_hidden = encoder(input_tensor)\n","        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n","        \n","        _, topi = decoder_outputs.topk(1)\n","        decoded_ids = topi.squeeze(-1)\n","    return decoded_ids\n","\n","source, target = random.choice(pairs)\n","predicted = get_prediction(source, encoder, decoder, input_lang)\n","print(f\"predicted : {predicted}\")"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T06:54:01.638995Z","iopub.status.busy":"2024-07-16T06:54:01.638660Z","iopub.status.idle":"2024-07-16T06:54:01.644859Z","shell.execute_reply":"2024-07-16T06:54:01.644001Z","shell.execute_reply.started":"2024-07-16T06:54:01.638967Z"},"trusted":true},"outputs":[],"source":["\"\"\"\n","accuracy metric definition\n","\"\"\"\n","\n","def create_ngrams(x , n):\n","    return x.unfold(1,n,1)\n","\n","def accuracy(predicted, target, ngram=1):\n","    predicted_ngrams = create_ngrams(predicted, ngram)\n","    target_ngrams = create_ngrams(target, ngram)\n","    matches = (predicted_ngrams == target_ngrams).all(dim=2)\n","    num = matches.sum()\n","    denom = matches.numel()\n","    #print(f\"matches : {num} , denom : {denom}\")\n","    return num / denom"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T06:54:02.369578Z","iopub.status.busy":"2024-07-16T06:54:02.368960Z","iopub.status.idle":"2024-07-16T06:54:02.417461Z","shell.execute_reply":"2024-07-16T06:54:02.416531Z","shell.execute_reply.started":"2024-07-16T06:54:02.369547Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["metric for a single random item 0.3799999952316284/1.0\n"]}],"source":["\"\"\"\n","generic metric calculator. f is the metric function\n","\"\"\"\n","def metric(f, encoder, decoder):\n","    pair = random.choice(pairs)\n","    target_ids = np.full((1, MAX_LENGTH_OUTPUT),  PADDING_token,  dtype=np.int32)\n","    target = indexesFromSentence(output_lang, pair[1])\n","    target.append(EOS_token)\n","    target_ids[0, : len(target)] = target\n","    \n","    predicted = get_prediction(pair[0], encoder, decoder, input_lang)\n","    \n","    return f(predicted, torch.tensor(target_ids).to(device))\n","\n","x = metric(accuracy, encoder, decoder)\n","print(f\"metric for a single random item {x.item()}/1.0\")"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T06:54:05.542948Z","iopub.status.busy":"2024-07-16T06:54:05.542035Z","iopub.status.idle":"2024-07-16T06:54:10.009081Z","shell.execute_reply":"2024-07-16T06:54:10.008136Z","shell.execute_reply.started":"2024-07-16T06:54:05.542916Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy metric: 0.9999993443489075\n"]}],"source":["\"\"\"\n","actual metric calculation with a stroed model\n","\"\"\"\n","\n","def metric(f, encoder, decoder):\n","    acc = 0.0\n","    num = 0 \n","    for data in test_loader:\n","        input_tensor, target_tensor = data\n","        batch_size = input_tensor.size(0)\n","        encoder_outputs, encoder_hidden = encoder(input_tensor)\n","        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden)\n","        decoder_outputs = ((decoder_outputs.topk(1)[1]).squeeze(-1))\n","        t_acc = f(decoder_outputs, target_tensor)\n","        acc = ( (t_acc * batch_size) + (acc * num) ) / (num + batch_size)\n","        num = num + batch_size\n","    return acc\n","        \n","e, d = get_trained_models(\"encoder-trial-10\", \"decoder-trial-10\")\n","\n","m = metric(accuracy, e, d)\n","print(f\"Accuracy metric: {m.item()/1.0}\")"]},{"cell_type":"markdown","metadata":{},"source":["**This completes my implementation. I will list some improvements that I am thinking of here for completeness:**\n","\n","1. I can include more type of layers. Right now I am using Linear and Conv2d layers. It will be easy to add ReLU and MaxPool layers. I'll have to spend some time for adding other types of layers if I wish to maintain \"shape compatibility\" between layers.\n","\n","2. I am just using Sequential layers right now. I could use generic Module derived classes. Again, that will be work in the synthetic data generation segment\n","\n","3. Can increase num layers in the models. Right now it's upto 6 layers. This will increase MAX_LENGTH for input so I'll have to see how the RNN handles that.\n","\n","4. Can add more metrics based on precision and recall. (something similar to BLEU or ROGUE). May also think about \"PADDING\" matches to have a lower weight for metric calculations"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-07-16T06:23:20.369049Z","iopub.status.idle":"2024-07-16T06:23:20.369550Z","shell.execute_reply":"2024-07-16T06:23:20.369313Z","shell.execute_reply.started":"2024-07-16T06:23:20.369293Z"},"id":"MZzwSopcjiNy","outputId":"cf649614-d576-4062-fcd9-c81e37c0707b","trusted":true},"outputs":[],"source":["\"\"\"\n","OLD SIMPLE IMPLEMENTATION OF SYNTHETIC DATA GENERATION. NOT USED NOW.\n","\"\"\"\n","\n","\n","\"\"\"\n","simple_synthetic_data_generator generates a single synthetic input\n","\n","for simplicity, I have used only Linear and Conv1d layers as part of my Input.\n","\"\"\"\n","\n","def get_shape_helper(model, stage):\n","  if isinstance(model, nn.Linear):\n","    if stage == \"input\":\n","      return f\"(b, {model.in_features})\"\n","    elif stage == \"output\":\n","      return f\"(b, {model.out_features})\"\n","  if isinstance(model, nn.Conv1d):\n","    if stage == \"input\":\n","      return f\"(b, {model.in_channels}, l)\"\n","    elif stage == \"output\":\n","      return f\"(b, {model.out_channels}, l)\"\n","  return NotImplementedError()\n","\n","\n","def simple_synthetic_data_generator(model):\n","  children = list(model.named_children())\n","  desc = f\"this model has {len(children)} layers.\"\n","  if(len(children) > 0):\n","    desc = desc + f\" the input has shape {get_shape_helper(children[0][1], 'input')} and the output has shape {get_shape_helper(children[-1][1], 'output')}\"\n","  return desc\n","\n","\"\"\"\n","test to see input for non empty model\n","\"\"\"\n","\n","def non_empty_model_test():\n","  non_empty_model = nn.Sequential(nn.Linear(12,30), nn.Linear(30,1))\n","  print(simple_synthetic_data_generator(non_empty_model))\n","non_empty_model_test()\n","\n","\n","\"\"\"\n","test to see input for empty model\n","\"\"\"\n","\n","def empty_model_test():\n","  empty_model = nn.Sequential()\n","  print(simple_synthetic_data_generator(empty_model))\n","empty_model_test()\n","\n","\"\"\"\n","Assume that each layer has 0-9 input and output number of nodes / kernels etc.\n","\"\"\"\n","\n","def get_random_sizes_for_layers(dims):\n","  return np.random.randint(0, 10, dims)\n","\n","\"\"\"\n","Create a synthetic dataset.\n","\n","The random selection of layers here means that the created synthetic model may throw runtime errors. \n","However, that is not a problem for the task at hand. In fact, the random selection of layers and dims in the synthetic \n","dataset means our trained seq2seq model learns a harder task as there is less \"structure\" in our synthetic models. \n","\"\"\"\n","\n","NUM_ITEMS = 20000\n","\n","def create_dataset_old(num_items):\n","  layer_options = [(nn.Linear, 2), (nn.Conv1d, 3)] # use linear and conv1d layers\n","  len_layer_optins = len(layer_options)\n","  data_pairs = []\n","  for item in range(num_items):\n","    num_layers = np.random.randint(0,6) # assume 0-2 layers only\n","    layers = []\n","    for _ in range(num_layers):\n","      layer_tuple = layer_options[np.random.randint(0,len(layer_options))] # pick layer type\n","      layer = layer_tuple[0]\n","      dims = layer_tuple[1]\n","      layers.append(layer(*get_random_sizes_for_layers(dims))) # add layer to architecture\n","    model = nn.Sequential(*layers)\n","    data_pairs.append({\"model\": model.__str__(), \"desc\": simple_synthetic_data_generator(model)})\n","  return data_pairs\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
