{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"I have chosen the NLP problem from here: https://drive.google.com/drive/folders/1oxnjzFQXIll5OUX7kaCyrE8FIKdFdeuV\n\nThe requirements are not precise so i will just note down my assumptions at the top here and also call them out as part of the comments in code:\n\n1. What should be the **synthetically created** input and output of the model ?\n\n- **Input** : What should be the input to the model ? \n\n\tThe doc says - \"(input should be) ... the architecture of a neural network created in PyTorch.This includes detailed information about its layers, configurations, and parameters.\" \n\n\tThere are several options which can be considered here:\n\n\ta) serialise the model and use the serialised string as input\n\tb) use the ouput of `__str__()` method of the model\n\tc) use a library like https://pypi.org/project/torch-summary/ to create it.\n\n\tIt will be the toughest for the model to learn from (a) above . (b) & (c) should be comparable.\n\n\tFor simplicity i have gone with (b) - using `model.__str__()` for input.\n \n-  **Output**: What should be the output of the model ?\n\n\tA couple of options here are: \n\n\ta) use a large language model to generate the output (openAI api/self-hosted LLAMA)\n\tb) write a simple function on my own.\n\t\t\n\tFor simplicity, I have gone with (b)\n\n2. Which **model** should I use ?\n\t\n\tThe doc says a \"seq2seq\" model. The term seq2seq is most often used in the context of a RNN (encoder + decoder) based architecture, with or without attention. Although some people also use it in the context of transformer based architecture, but that is rare.\n\t\n\tI have gone with RNN based encoder/decoder arch with attention and adapted my model from here: https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n    \n    The choice of seq2seq model means that it typically performs well with input sizes of about 30-50 characters. The sizes I have taken are longer but the model performs reasonably well.","metadata":{}},{"cell_type":"code","source":"\"\"\"\nAll imports at the top\n\"\"\"\n\nfrom __future__ import unicode_literals, print_function, division\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler\n\n\nfrom io import open\nimport unicodedata\nimport re\nimport random\nfrom time import time\nimport math\nimport numpy as np\nimport json\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"id":"O3Y061k9BEwF","execution":{"iopub.status.busy":"2024-07-16T06:15:11.150153Z","iopub.execute_input":"2024-07-16T06:15:11.150889Z","iopub.status.idle":"2024-07-16T06:15:14.828354Z","shell.execute_reply.started":"2024-07-16T06:15:11.150857Z","shell.execute_reply":"2024-07-16T06:15:14.827291Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nA sample of the synthetically generated input I will be using\n\"\"\"\n\nsample = nn.Sequential(nn.Linear(2,10), nn.Linear(10,25), nn.Conv1d(25, 3, 1))\nsample.__str__()","metadata":{"id":"6uNx4uYkQV90","execution":{"iopub.status.busy":"2024-07-16T06:15:14.830199Z","iopub.execute_input":"2024-07-16T06:15:14.830644Z","iopub.status.idle":"2024-07-16T06:15:14.860207Z","shell.execute_reply.started":"2024-07-16T06:15:14.830615Z","shell.execute_reply":"2024-07-16T06:15:14.859266Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"'Sequential(\\n  (0): Linear(in_features=2, out_features=10, bias=True)\\n  (1): Linear(in_features=10, out_features=25, bias=True)\\n  (2): Conv1d(25, 3, kernel_size=(1,), stride=(1,))\\n)'"},"metadata":{}}]},{"cell_type":"code","source":"\"\"\"\nHelper functions to create synthetic data\n\"\"\"\n\nNUM_ITEMS = 20000\ndef find_divisors(n):\n    # Handle edge case for non-positive numbers\n    if n <= 0:\n        return []\n    \n    divisors = []\n    for i in range(1, int(n**0.5) + 1):\n        if n % i == 0:\n            divisors.append(i)\n            if i != n // i:  # Avoid duplicates for perfect squares\n                divisors.append(n // i)\n    \n    return sorted(divisors)\n\n\ndef perfect_square_root(n):\n    if n < 0:\n        return None\n    \n    root = int(math.sqrt(n))\n    \n    if root * root == n:\n        return root\n    else:\n        return None\n\n\n\ndef get_dims_helper(dims_left):\n    divs = find_divisors(dims_left)\n    for div in divs:\n        n_2 = dims_left // div\n        root = perfect_square_root(n_2)\n        if root is not None:\n            return div, root, root\n    return dims_left, 1, 1\n\ndef get_out_dims_helper(dims_left, h):\n    divs = find_divisors(dims_left)\n    for div in divs:\n        n_2 = dims_left // div\n        root = perfect_square_root(n_2)\n        if root is not None:\n            k = h - root + 1\n            if k > 0:\n                return div, k\n    return dims_left, h\n        \n\nclass Reshape(nn.Module):\n    def __init__(self, size):\n        super().__init__()\n        self.size = size\n    \n    def forward(self,x):\n        return x.view(*self.size)","metadata":{"execution":{"iopub.status.busy":"2024-07-16T06:15:14.861222Z","iopub.execute_input":"2024-07-16T06:15:14.861516Z","iopub.status.idle":"2024-07-16T06:15:14.873864Z","shell.execute_reply.started":"2024-07-16T06:15:14.861491Z","shell.execute_reply":"2024-07-16T06:15:14.872940Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nGenerate one synthetic sample.\n\nI have made sure to create models that will \"work\". Random sizes for layer dimensions and layer placements\nwould still have been enough for learning the task at hand, but the incompatibility between layers \nwould have meant they would have thrown runtime errors in practice.\n\n\"\"\"\n\ndef get_one_sample():\n    layer_options = [nn.Linear, nn.Conv2d]\n    layers = []\n    sizes = []\n    num_layers = random.choice(range(0,6))\n    dim_choices = range(1,10)\n    curr = None\n    for layer_idx in range(num_layers):\n        layer_type = random.choice(layer_options)\n        if layer_idx == 0:\n            if layer_type == nn.Linear:\n                dims = [random.choice(dim_choices) for _ in range(2) ]\n                layers.append(nn.Linear(*dims))\n                sizes.append(([\"N\", dims[0]] , [\"N\", dims[1]]))\n                curr = (layers[-1](torch.ones(32 * dims[0]).view(32, dims[0])))\n            elif layer_type == nn.Conv2d:\n                dims = [random.choice(dim_choices) for _ in range(3)]\n                layers.append(nn.Conv2d(*dims))\n                sizes.append(([\"N\" , dims[0], \"H\", \"W\"], [\"N\", dims[1], f\"H-{dims[2]}+1\", f\"W-{dims[2]}+1\"]))\n                curr = (layers[-1](torch.ones(32 * dims[0]* 64 * 64).view(32, dims[0], 64, 64)))\n        else:\n                size = curr.size()\n                if layer_type == nn.Linear:\n                    if isinstance(layers[-1] , nn.Linear):\n                        dims = [size[1], random.choice(dim_choices)]\n                        layers.append(nn.Linear(*dims))\n                        sizes.append(([\"N\", dims[0]], [\"N\", dims[1]]))\n                        curr = (layers[-1](curr))\n                    elif isinstance(layers[-1] , nn.Conv2d):\n                        layers.append(Reshape([size[0], -1]))\n                        curr = layers[-1](curr)\n                        dims = [curr.size()[1], random.choice(dim_choices)]\n                        layers.append(nn.Linear(*dims))\n                        sizes.append(([\"N\", dims[0]], [\"N\", dims[1]]))\n                        curr = (layers[-1](curr))\n                elif layer_type == nn.Conv2d:\n                    if isinstance(layers[-1] , nn.Linear):\n                        dims_left = curr.numel() // size[0]\n                        c, h, w = get_dims_helper(dims_left) \n                        layers.append(Reshape([size[0], c, h, w] ))\n                        curr = layers[-1](curr)\n                        co, k = get_out_dims_helper(dims_left, h)\n                        dims = [c, co, k]\n                        layers.append(nn.Conv2d(*dims))\n                        sizes.append(([\"N\", c, h, w], [\"N\", co, h-k+1, h-k+1]))\n                        curr = layers[-1](curr)\n                    else:\n                        continue\n    in_dim = sizes[0][0] if len(sizes) > 0 else None\n    out_dim = sizes[-1][1] if len(sizes) > 0 else None\n    return nn.Sequential(*layers), in_dim, out_dim","metadata":{"execution":{"iopub.status.busy":"2024-07-16T06:15:14.875982Z","iopub.execute_input":"2024-07-16T06:15:14.876310Z","iopub.status.idle":"2024-07-16T06:15:14.895299Z","shell.execute_reply.started":"2024-07-16T06:15:14.876279Z","shell.execute_reply":"2024-07-16T06:15:14.894360Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nSimple description for a model\n\"\"\"\n\ndef get_description(n,i,o):\n    base =  f\"this model has {n} layers.\"\n    if i != None:\n        i = i.__str__().replace(\"'\", \"\")\n        base = base + f\"the input has shape {i}.\"\n    if o != None:\n        o = o.__str__().replace(\"'\", \"\")\n        base = base + f\"the output has shape {o}\"\n    return base\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-16T06:15:14.896231Z","iopub.execute_input":"2024-07-16T06:15:14.896471Z","iopub.status.idle":"2024-07-16T06:15:14.906014Z","shell.execute_reply.started":"2024-07-16T06:15:14.896451Z","shell.execute_reply":"2024-07-16T06:15:14.905293Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"\"\"\"\ncreate dataset in memory\n\"\"\"\n\ndef create_dataset(num_samples, report_after=4000):\n    data_pairs = []\n    for idx in range(num_samples):\n        m, i ,o = get_one_sample()\n        n = len(list(m.named_children()))\n        data_pairs.append({\"model\": m.__str__(), \"desc\": get_description(n, i, o)})\n        if idx % report_after == 0 and idx >= report_after:\n            print(f\"wrote {idx} items to disk ....\")\n    return data_pairs\n\ndp = create_dataset(2000)\ndp[:10]","metadata":{"execution":{"iopub.status.busy":"2024-07-16T06:15:14.907058Z","iopub.execute_input":"2024-07-16T06:15:14.907361Z","iopub.status.idle":"2024-07-16T06:15:20.653446Z","shell.execute_reply.started":"2024-07-16T06:15:14.907329Z","shell.execute_reply":"2024-07-16T06:15:20.652489Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"[{'model': 'Sequential(\\n  (0): Linear(in_features=3, out_features=7, bias=True)\\n  (1): Reshape()\\n  (2): Conv2d(7, 7, kernel_size=(1, 1), stride=(1, 1))\\n  (3): Reshape()\\n  (4): Linear(in_features=7, out_features=9, bias=True)\\n  (5): Linear(in_features=9, out_features=6, bias=True)\\n)',\n  'desc': 'this model has 6 layers.the input has shape [N, 3].the output has shape [N, 6]'},\n {'model': 'Sequential(\\n  (0): Conv2d(6, 3, kernel_size=(6, 6), stride=(1, 1))\\n)',\n  'desc': 'this model has 1 layers.the input has shape [N, 6, H, W].the output has shape [N, 3, H-6+1, W-6+1]'},\n {'model': 'Sequential(\\n  (0): Linear(in_features=8, out_features=3, bias=True)\\n  (1): Linear(in_features=3, out_features=7, bias=True)\\n  (2): Linear(in_features=7, out_features=1, bias=True)\\n  (3): Reshape()\\n  (4): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1))\\n)',\n  'desc': 'this model has 5 layers.the input has shape [N, 8].the output has shape [N, 1, 1, 1]'},\n {'model': 'Sequential()', 'desc': 'this model has 0 layers.'},\n {'model': 'Sequential(\\n  (0): Conv2d(3, 6, kernel_size=(8, 8), stride=(1, 1))\\n  (1): Reshape()\\n  (2): Linear(in_features=19494, out_features=7, bias=True)\\n)',\n  'desc': 'this model has 3 layers.the input has shape [N, 3, H, W].the output has shape [N, 7]'},\n {'model': 'Sequential()', 'desc': 'this model has 0 layers.'},\n {'model': 'Sequential(\\n  (0): Linear(in_features=9, out_features=1, bias=True)\\n  (1): Reshape()\\n  (2): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1))\\n)',\n  'desc': 'this model has 3 layers.the input has shape [N, 9].the output has shape [N, 1, 1, 1]'},\n {'model': 'Sequential()', 'desc': 'this model has 0 layers.'},\n {'model': 'Sequential(\\n  (0): Conv2d(3, 6, kernel_size=(6, 6), stride=(1, 1))\\n  (1): Reshape()\\n  (2): Linear(in_features=20886, out_features=8, bias=True)\\n  (3): Reshape()\\n  (4): Conv2d(2, 2, kernel_size=(1, 1), stride=(1, 1))\\n)',\n  'desc': 'this model has 5 layers.the input has shape [N, 3, H, W].the output has shape [N, 2, 2, 2]'},\n {'model': 'Sequential(\\n  (0): Conv2d(5, 9, kernel_size=(7, 7), stride=(1, 1))\\n  (1): Reshape()\\n  (2): Linear(in_features=30276, out_features=6, bias=True)\\n)',\n  'desc': 'this model has 3 layers.the input has shape [N, 5, H, W].the output has shape [N, 6]'}]"},"metadata":{}}]},{"cell_type":"code","source":"\"\"\"\nwrite dataset to disk\n\"\"\"\n\ndef write_dataset():\n  data = create_dataset(NUM_ITEMS)\n  json_data = json.dumps(data)\n  json_data\n\n  with open(\"simple_data.json\", \"w\") as f:\n    f.write(json_data)\n  print(f\"created a synthetic dataset with number of items: {len(data)} and saved to disk\")\n  print(f\"sample dataset entry:\\n input: {data[0]['model']}\\n output: {data[0]['desc']}\")\n\nwrite_dataset()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-16T06:15:20.654495Z","iopub.execute_input":"2024-07-16T06:15:20.654793Z","iopub.status.idle":"2024-07-16T06:16:12.130155Z","shell.execute_reply.started":"2024-07-16T06:15:20.654767Z","shell.execute_reply":"2024-07-16T06:16:12.129162Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"wrote 4000 items to disk ....\nwrote 8000 items to disk ....\nwrote 12000 items to disk ....\nwrote 16000 items to disk ....\ncreated a synthetic dataset with number of items: 20000 and saved to disk\nsample dataset entry:\n input: Sequential(\n  (0): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1))\n)\n output: this model has 1 layers.the input has shape [N, 8, H, W].the output has shape [N, 8, H-1+1, W-1+1]\n","output_type":"stream"}]},{"cell_type":"code","source":"\"\"\"\nclass to create a Vocabulary\n\"\"\"\n\nSOS_token = 0\nEOS_token = 1\nPADDING_token = 2\n\nclass Lang:\n    def __init__(self, name):\n        self.name = name\n        self.word2index = {}\n        self.word2count = {}\n        self.index2word = {0: \"SOS\", 1: \"EOS\", 2: \"PADDING\"}\n        self.n_words = 2  # Count SOS and EOS\n\n    def addSentence(self, sentence):\n        for word in sentence.split(' '):\n            if word.isdigit():\n              self.addInteger(word)\n            else:\n              self.addWord(word)\n\n    def addInteger(self, word):\n      for digit in word:\n        self.addWord(word)\n\n    def addWord(self, word):\n        if word not in self.word2index:\n            self.word2index[word] = self.n_words\n            self.word2count[word] = 1\n            self.index2word[self.n_words] = word\n            self.n_words += 1\n        else:\n            self.word2count[word] += 1","metadata":{"id":"S_npuYpdAxzp","execution":{"iopub.status.busy":"2024-07-16T06:16:12.131570Z","iopub.execute_input":"2024-07-16T06:16:12.131936Z","iopub.status.idle":"2024-07-16T06:16:12.140966Z","shell.execute_reply.started":"2024-07-16T06:16:12.131903Z","shell.execute_reply":"2024-07-16T06:16:12.139921Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"\"\"\"\ndata preprocessing helper: normalise input and output\n\"\"\"\n\ndef normalizeString(s):\n    s = re.sub(r\"([.!?()=,])\", r\" \\1 \", s)\n#     s = re.sub(r\"([():,=\\n])\", r\"\", s)\n#     s = re.sub(r\"  \", r\" \", s)\n    return s.lower().strip()\n\nx = normalizeString(\"Sequential(\\n  (0): Conv1d(7, 1, kernel_size=(3,), stride=(1,))\\n  (1): Linear(in_features=8, out_features=1, bias=True)\\n)\")\nx","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"id":"Ev-rFDeNA3SZ","outputId":"b3c4298e-477f-4dc5-f421-f40065ed2bea","execution":{"iopub.status.busy":"2024-07-16T06:16:12.142029Z","iopub.execute_input":"2024-07-16T06:16:12.142349Z","iopub.status.idle":"2024-07-16T06:16:12.153277Z","shell.execute_reply.started":"2024-07-16T06:16:12.142325Z","shell.execute_reply":"2024-07-16T06:16:12.152269Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"'sequential ( \\n   ( 0 ) : conv1d ( 7 ,  1 ,  kernel_size =  ( 3 ,  )  ,  stride =  ( 1 ,  )  ) \\n   ( 1 ) : linear ( in_features = 8 ,  out_features = 1 ,  bias = true ) \\n )'"},"metadata":{}}]},{"cell_type":"code","source":"\"\"\"\nHelper function to read data from disk and create vocabularies\n\"\"\"\n\ndef load_data():\n    print(\"Reading lines...\")\n\n    # Read the file and split into lines\n    lines = []\n    with open('simple_data.json') as f:\n      lines = json.load(f)\n\n    pairs = [[normalizeString(item[\"model\"]), normalizeString(item[\"desc\"])] for item in lines]\n    input_lang = Lang(\"model\")\n    output_lang = Lang(\"desc\")\n\n    return input_lang, output_lang, pairs","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-KG6ufIz97EW","outputId":"eb7c24d8-e52f-43e8-b67e-dc177f244584","execution":{"iopub.status.busy":"2024-07-16T06:16:12.157048Z","iopub.execute_input":"2024-07-16T06:16:12.157362Z","iopub.status.idle":"2024-07-16T06:16:12.163050Z","shell.execute_reply.started":"2024-07-16T06:16:12.157339Z","shell.execute_reply":"2024-07-16T06:16:12.162132Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nread data from disk and create vocabs\n\"\"\"\n\ndef prepareData():\n    input_lang, output_lang, pairs = load_data()\n    print(\"Read %s sentence pairs\" % len(pairs))\n    print(\"Counting words...\")\n    for pair in pairs:\n        input_lang.addSentence(pair[0])\n        output_lang.addSentence(pair[1])\n    print(\"Counted words:\")\n    print(input_lang.name, input_lang.n_words)\n    print(output_lang.name, output_lang.n_words)\n    return input_lang, output_lang, pairs\n\ninput_lang, output_lang, pairs = prepareData()\nrandom_pair = random.choice(pairs)\nprint(f\"A random input/output pair : {random_pair}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dNrT_fMmAp03","outputId":"e44deeb9-769a-4c4f-8bf8-d0dd1635c442","execution":{"iopub.status.busy":"2024-07-16T06:16:12.164177Z","iopub.execute_input":"2024-07-16T06:16:12.164465Z","iopub.status.idle":"2024-07-16T06:16:14.710344Z","shell.execute_reply.started":"2024-07-16T06:16:12.164443Z","shell.execute_reply":"2024-07-16T06:16:14.709297Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Reading lines...\nRead 20000 sentence pairs\nCounting words...\nCounted words:\nmodel 110\ndesc 53\nA random input/output pair : ['sequential ( \\n   ( 0 ) : linear ( in_features = 4 ,  out_features = 6 ,  bias = true ) \\n   ( 1 ) : linear ( in_features = 6 ,  out_features = 8 ,  bias = true ) \\n   ( 2 ) : reshape (  ) \\n   ( 3 ) : conv2d ( 2 ,  2 ,  kernel_size =  ( 1 ,  1 )  ,  stride =  ( 1 ,  1 )  ) \\n )', 'this model has 4 layers . the input has shape [n ,  4] . the output has shape [n ,  2 ,  2 ,  2]']\n","output_type":"stream"}]},{"cell_type":"code","source":"\"\"\"\nHelper functions\n\"\"\"\n\ndef indexesFromSentence(lang, sentence):\n    return [lang.word2index[word] for word in sentence.split(' ')]\n\ndef tensorFromSentence(lang, sentence):\n    indexes = indexesFromSentence(lang, sentence)\n    indexes.append(EOS_token)\n    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n\ndef tensorsFromPair(pair):\n    input_tensor = tensorFromSentence(input_lang, pair[0])\n    target_tensor = tensorFromSentence(output_lang, pair[1])\n    return (input_tensor, target_tensor)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nsw9v84sDUjk","outputId":"fb77dc06-828d-4d8e-f2ab-108eb873cfd8","execution":{"iopub.status.busy":"2024-07-16T06:16:14.712160Z","iopub.execute_input":"2024-07-16T06:16:14.712555Z","iopub.status.idle":"2024-07-16T06:16:14.720075Z","shell.execute_reply.started":"2024-07-16T06:16:14.712520Z","shell.execute_reply":"2024-07-16T06:16:14.719121Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nEmpirically test max length of input and output\n\"\"\"\n\ndef maxLength(l,lang):\n  m = len(indexesFromSentence(lang, l[0]))\n  for s in l:\n    if len(indexesFromSentence(lang, s)) > m:\n      m = len(indexesFromSentence(lang,s))\n  return m\n\nl1s = [item[0] for item in pairs]\nl2s = [item[1] for item in pairs]\nm1 = maxLength(l1s, input_lang)\nm2 = maxLength(l2s, output_lang)\nprint(f\"longest input sentence : {m1}.\\nlongest output sentence {m2}.\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MKKuzYUkK2Ez","outputId":"6dce8c59-e7fd-40ae-e969-532533b2ff82","execution":{"iopub.status.busy":"2024-07-16T06:16:14.721437Z","iopub.execute_input":"2024-07-16T06:16:14.721750Z","iopub.status.idle":"2024-07-16T06:16:15.018531Z","shell.execute_reply.started":"2024-07-16T06:16:14.721713Z","shell.execute_reply":"2024-07-16T06:16:15.017487Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"longest input sentence : 208.\nlongest output sentence 35.\n","output_type":"stream"}]},{"cell_type":"code","source":"\"\"\"\nset input and output max length\n\"\"\"\n\nMAX_LENGTH_INPUT = 220\nMAX_LENGTH_OUTPUT = 50","metadata":{"id":"84Swpy-vPf1z","execution":{"iopub.status.busy":"2024-07-16T06:16:15.019928Z","iopub.execute_input":"2024-07-16T06:16:15.020271Z","iopub.status.idle":"2024-07-16T06:16:15.024187Z","shell.execute_reply.started":"2024-07-16T06:16:15.020245Z","shell.execute_reply":"2024-07-16T06:16:15.023342Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nCreate a dataloader\n\"\"\"\ndef helper(inputs, targets, l, r):\n    input_ids = inputs[l :  r, :]\n    target_ids = targets[l: r, :]\n    data = TensorDataset(torch.LongTensor(input_ids).to(device),\n                               torch.LongTensor(target_ids).to(device))\n    sampler = RandomSampler(data)\n    dataloader = DataLoader(data, sampler=sampler, batch_size=batch_size)\n    return dataloader\n    \ndef get_dataloader(batch_size, test_split = 0.2):\n    input_lang, output_lang, pairs = prepareData()\n\n    n = len(pairs)\n    input_ids = np.full((n, MAX_LENGTH_INPUT), PADDING_token ,dtype=np.int32)\n    target_ids = np.full((n, MAX_LENGTH_OUTPUT),  PADDING_token,  dtype=np.int32)\n\n    for idx, (inp, tgt) in enumerate(pairs):\n        inp_ids = indexesFromSentence(input_lang, inp)\n        tgt_ids =  indexesFromSentence(output_lang, tgt)\n        inp_ids.append(EOS_token)\n        tgt_ids.append(EOS_token)\n        input_ids[idx, :len(inp_ids)] = inp_ids\n        target_ids[idx, :len(tgt_ids)] = tgt_ids\n    \n    test_size = int(test_split * n)\n    train_size = n - test_size\n    \n    print(f\"train size: {train_size}. test size: {test_size}\")\n    train_dataloader = helper(input_ids, target_ids, 0, train_size)\n    test_dataloader = helper(input_ids, target_ids, train_size, n)\n    \n    \n    return input_lang, output_lang, train_dataloader, test_dataloader","metadata":{"id":"gnSMBHl1JAwa","execution":{"iopub.status.busy":"2024-07-16T06:16:15.025605Z","iopub.execute_input":"2024-07-16T06:16:15.025916Z","iopub.status.idle":"2024-07-16T06:16:15.038330Z","shell.execute_reply.started":"2024-07-16T06:16:15.025891Z","shell.execute_reply":"2024-07-16T06:16:15.037455Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nEncoder RNN\n\"\"\"\nclass EncoderRNN(nn.Module):\n    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n        super(EncoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n\n        self.embedding = nn.Embedding(input_size, hidden_size)\n        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n        self.dropout = nn.Dropout(dropout_p)\n\n    def forward(self, input):\n        embedded = self.dropout(self.embedding(input))\n        output, hidden = self.gru(embedded)\n        return output, hidden","metadata":{"id":"bS6VvX5LRkSn","execution":{"iopub.status.busy":"2024-07-16T06:16:15.039761Z","iopub.execute_input":"2024-07-16T06:16:15.040036Z","iopub.status.idle":"2024-07-16T06:16:15.047345Z","shell.execute_reply.started":"2024-07-16T06:16:15.040014Z","shell.execute_reply":"2024-07-16T06:16:15.046519Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nDecoder RNN. The code is written so that we have the option of using teacher forcing at runtime.\nIn practice, teacher forcing works very well.\n\"\"\"\n\nclass DecoderRNN(nn.Module):\n    def __init__(self, hidden_size, output_size):\n        super(DecoderRNN, self).__init__()\n        self.embedding = nn.Embedding(output_size, hidden_size)\n        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n        self.out = nn.Linear(hidden_size, output_size)\n\n    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n        batch_size = encoder_outputs.size(0)\n        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n        decoder_hidden = encoder_hidden\n        decoder_outputs = []\n\n        for i in range(MAX_LENGTH_OUTPUT):\n            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n            decoder_outputs.append(decoder_output)\n\n            if target_tensor is not None:\n                # Teacher forcing: Feed the target as the next input\n                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n            else:\n                # Without teacher forcing: use its own predictions as the next input\n                _, topi = decoder_output.topk(1)\n                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n\n        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n        return decoder_outputs, decoder_hidden, None # We return `None` for consistency in the training loop\n\n    def forward_step(self, input, hidden):\n        output = self.embedding(input)\n        output = F.relu(output)\n        output, hidden = self.gru(output, hidden)\n        output = self.out(output)\n        return output, hidden\n\n  \n    \nclass BahdanauAttention(nn.Module):\n    def __init__(self, hidden_size):\n        super(BahdanauAttention, self).__init__()\n        self.Wa = nn.Linear(hidden_size, hidden_size)\n        self.Ua = nn.Linear(hidden_size, hidden_size)\n        self.Va = nn.Linear(hidden_size, 1)\n\n    def forward(self, query, keys):\n        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n        scores = scores.squeeze(2).unsqueeze(1)\n\n        weights = F.softmax(scores, dim=-1)\n        context = torch.bmm(weights, keys)\n\n        return context, weights\n\n\"\"\"\nDecoder RNN with attention\n\"\"\"      \nclass AttnDecoderRNN(nn.Module):\n    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n        super(AttnDecoderRNN, self).__init__()\n        self.embedding = nn.Embedding(output_size, hidden_size)\n        self.attention = BahdanauAttention(hidden_size)\n        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n        self.out = nn.Linear(hidden_size, output_size)\n        self.dropout = nn.Dropout(dropout_p)\n\n    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n        batch_size = encoder_outputs.size(0)\n        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n        decoder_hidden = encoder_hidden\n        decoder_outputs = []\n        attentions = []\n\n        for i in range(MAX_LENGTH_OUTPUT):\n            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n                decoder_input, decoder_hidden, encoder_outputs\n            )\n            decoder_outputs.append(decoder_output)\n            attentions.append(attn_weights)\n\n            if target_tensor is not None:\n                # Teacher forcing: Feed the target as the next input\n                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n            else:\n                # Without teacher forcing: use its own predictions as the next input\n                _, topi = decoder_output.topk(1)\n                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n\n        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n        attentions = torch.cat(attentions, dim=1)\n\n        return decoder_outputs, decoder_hidden, attentions\n\n\n    def forward_step(self, input, hidden, encoder_outputs):\n        embedded =  self.dropout(self.embedding(input))\n\n        query = hidden.permute(1, 0, 2)\n        context, attn_weights = self.attention(query, encoder_outputs)\n        input_gru = torch.cat((embedded, context), dim=2)\n\n        output, hidden = self.gru(input_gru, hidden)\n        output = self.out(output)\n\n        return output, hidden, attn_weights\n\n","metadata":{"id":"7l_R4_NGRqex","execution":{"iopub.status.busy":"2024-07-16T06:16:15.048576Z","iopub.execute_input":"2024-07-16T06:16:15.048909Z","iopub.status.idle":"2024-07-16T06:16:15.073108Z","shell.execute_reply.started":"2024-07-16T06:16:15.048875Z","shell.execute_reply":"2024-07-16T06:16:15.072364Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"\"\"\"\ntrain one epoch\n\"\"\"\n\ndef train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n          decoder_optimizer, criterion, epoch, print_every = 100 ):\n\n    total_loss = 0\n    t = time()\n    idx = 0\n    for data in dataloader:\n\n        input_tensor, target_tensor = data\n\n        encoder_optimizer.zero_grad()\n        decoder_optimizer.zero_grad()\n\n        encoder_outputs, encoder_hidden = encoder(input_tensor)\n        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n\n        loss = criterion(\n            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n            target_tensor.view(-1)\n        )\n        loss.backward()\n\n        encoder_optimizer.step()\n        decoder_optimizer.step()\n\n        total_loss += loss.item()\n\n        if(idx % print_every == 0 and idx != 0):\n          print(f\"batches : {idx-print_every} - {idx}  of epoch {epoch} took time: {time() - t}.\")\n          t = time()\n        idx = idx+1\n\n    return total_loss / len(dataloader)","metadata":{"execution":{"iopub.status.busy":"2024-07-16T06:16:15.074152Z","iopub.execute_input":"2024-07-16T06:16:15.074444Z","iopub.status.idle":"2024-07-16T06:16:15.084020Z","shell.execute_reply.started":"2024-07-16T06:16:15.074419Z","shell.execute_reply":"2024-07-16T06:16:15.083280Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nhelper functions\n\"\"\"\n\ndef asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\ndef timeSince(since, percent):\n    now = time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))","metadata":{"id":"U1RUVe44RF59","execution":{"iopub.status.busy":"2024-07-16T06:16:15.085156Z","iopub.execute_input":"2024-07-16T06:16:15.085506Z","iopub.status.idle":"2024-07-16T06:16:15.092164Z","shell.execute_reply.started":"2024-07-16T06:16:15.085472Z","shell.execute_reply":"2024-07-16T06:16:15.091345Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"\"\"\"\ndefine function for complete training\n\"\"\"\n\ndef train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n               print_every=100, plot_every=100, save_file_suffix = \"\"):\n    start = time()\n    plot_losses = []\n    print_loss_total = 0  # Reset every print_every\n    plot_loss_total = 0  # Reset every plot_every\n\n    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n    criterion = nn.NLLLoss()\n\n    for epoch in range(1, n_epochs + 1):\n        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, epoch = epoch)\n        print_loss_total += loss\n        plot_loss_total += loss\n\n        if epoch % print_every == 0:\n            torch.save(encoder.state_dict(), f\"./encoder-{save_file_suffix}-{epoch}\")\n            torch.save(decoder.state_dict(), f\"./decoder-{save_file_suffix}-{epoch}\")\n            print_loss_avg = print_loss_total / print_every\n            print_loss_total = 0\n            print('EPOCH %d done. %s (%d %d%%) avearage loss: %.4f' % (epoch, timeSince(start, epoch / n_epochs),\n                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n\n        if epoch % plot_every == 0:\n            plot_loss_avg = plot_loss_total / plot_every\n            plot_losses.append(plot_loss_avg)\n            plot_loss_total = 0\n","metadata":{"id":"6DYgHnE1RMng","execution":{"iopub.status.busy":"2024-07-16T06:46:35.019329Z","iopub.execute_input":"2024-07-16T06:46:35.019737Z","iopub.status.idle":"2024-07-16T06:46:35.029447Z","shell.execute_reply.started":"2024-07-16T06:46:35.019709Z","shell.execute_reply":"2024-07-16T06:46:35.028558Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nactual training\n\"\"\"\n\n\nhidden_size = 128\nbatch_size = 32\n\ninput_lang, output_lang, train_dataloader, test_loader = get_dataloader(batch_size)\n\nencoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\ndecoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n\ntrain(train_dataloader, encoder, decoder, 10 , print_every=1, plot_every=1, save_file_suffix=\"trial\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"EKEBQLTSRgil","outputId":"31c6466b-f844-4fe9-a24f-5c605f38f7ca","execution":{"iopub.status.busy":"2024-07-16T06:46:35.621650Z","iopub.execute_input":"2024-07-16T06:46:35.621972Z","iopub.status.idle":"2024-07-16T06:53:36.724476Z","shell.execute_reply.started":"2024-07-16T06:46:35.621947Z","shell.execute_reply":"2024-07-16T06:53:36.723543Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Reading lines...\nRead 20000 sentence pairs\nCounting words...\nCounted words:\nmodel 110\ndesc 53\ntrain size: 16000. test size: 4000\nbatches : 0 - 100  of epoch 1 took time: 8.473941802978516.\nbatches : 100 - 200  of epoch 1 took time: 8.34061861038208.\nbatches : 200 - 300  of epoch 1 took time: 8.379926919937134.\nbatches : 300 - 400  of epoch 1 took time: 8.469292402267456.\nEPOCH 1 done. 0m 42s (- 6m 18s) (1 10%) avearage loss: 0.2971\nbatches : 0 - 100  of epoch 2 took time: 8.423267841339111.\nbatches : 100 - 200  of epoch 2 took time: 8.37239670753479.\nbatches : 200 - 300  of epoch 2 took time: 8.450244903564453.\nbatches : 300 - 400  of epoch 2 took time: 8.290489196777344.\nEPOCH 2 done. 1m 23s (- 5m 35s) (2 20%) avearage loss: 0.0562\nbatches : 0 - 100  of epoch 3 took time: 8.436162233352661.\nbatches : 100 - 200  of epoch 3 took time: 8.402474164962769.\nbatches : 200 - 300  of epoch 3 took time: 8.35907769203186.\nbatches : 300 - 400  of epoch 3 took time: 8.267791748046875.\nEPOCH 3 done. 2m 5s (- 4m 53s) (3 30%) avearage loss: 0.0115\nbatches : 0 - 100  of epoch 4 took time: 8.50065541267395.\nbatches : 100 - 200  of epoch 4 took time: 8.351497888565063.\nbatches : 200 - 300  of epoch 4 took time: 8.286925792694092.\nbatches : 300 - 400  of epoch 4 took time: 8.320127248764038.\nEPOCH 4 done. 2m 47s (- 4m 11s) (4 40%) avearage loss: 0.0078\nbatches : 0 - 100  of epoch 5 took time: 8.401658535003662.\nbatches : 100 - 200  of epoch 5 took time: 8.30204153060913.\nbatches : 200 - 300  of epoch 5 took time: 8.372209310531616.\nbatches : 300 - 400  of epoch 5 took time: 8.464751958847046.\nEPOCH 5 done. 3m 29s (- 3m 29s) (5 50%) avearage loss: 0.0031\nbatches : 0 - 100  of epoch 6 took time: 8.402701377868652.\nbatches : 100 - 200  of epoch 6 took time: 8.497881174087524.\nbatches : 200 - 300  of epoch 6 took time: 8.32158350944519.\nbatches : 300 - 400  of epoch 6 took time: 8.274828910827637.\nEPOCH 6 done. 4m 11s (- 2m 47s) (6 60%) avearage loss: 0.0008\nbatches : 0 - 100  of epoch 7 took time: 8.475096940994263.\nbatches : 100 - 200  of epoch 7 took time: 8.233327865600586.\nbatches : 200 - 300  of epoch 7 took time: 8.347994565963745.\nbatches : 300 - 400  of epoch 7 took time: 8.330747842788696.\nEPOCH 7 done. 4m 52s (- 2m 5s) (7 70%) avearage loss: 0.0011\nbatches : 0 - 100  of epoch 8 took time: 8.387349128723145.\nbatches : 100 - 200  of epoch 8 took time: 8.341842412948608.\nbatches : 200 - 300  of epoch 8 took time: 8.278261661529541.\nbatches : 300 - 400  of epoch 8 took time: 8.402803897857666.\nEPOCH 8 done. 5m 34s (- 1m 23s) (8 80%) avearage loss: 0.0002\nbatches : 0 - 100  of epoch 9 took time: 8.476083755493164.\nbatches : 100 - 200  of epoch 9 took time: 8.560318231582642.\nbatches : 200 - 300  of epoch 9 took time: 8.321957349777222.\nbatches : 300 - 400  of epoch 9 took time: 8.331254243850708.\nEPOCH 9 done. 6m 16s (- 0m 41s) (9 90%) avearage loss: 0.0001\nbatches : 0 - 100  of epoch 10 took time: 8.526540756225586.\nbatches : 100 - 200  of epoch 10 took time: 8.293506383895874.\nbatches : 200 - 300  of epoch 10 took time: 8.320956945419312.\nbatches : 300 - 400  of epoch 10 took time: 8.299473285675049.\nEPOCH 10 done. 6m 58s (- 0m 0s) (10 100%) avearage loss: 0.0001\n","output_type":"stream"}]},{"cell_type":"code","source":"\"\"\"\nhelpers to load trained models\n\"\"\"\n\nimport os.path\n\n\ndef load_model(model, path):\n    model.load_state_dict(torch.load(path))\n    model.eval()\n    return model\n\ndef get_trained_models(save_path_encoder, save_path_decoder):\n    if os.path.isfile(save_path_encoder) and os.path.isfile(save_path_decoder):\n        e = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n        d = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n        e = load_model(e, save_path_encoder)\n        d = load_model(d, save_path_decoder)\n        return e, d\n    print(f\"pre trained weigths do not exist at given path\")\n    return None, None","metadata":{"execution":{"iopub.status.busy":"2024-07-16T06:53:45.975618Z","iopub.execute_input":"2024-07-16T06:53:45.976301Z","iopub.status.idle":"2024-07-16T06:53:45.983067Z","shell.execute_reply.started":"2024-07-16T06:53:45.976268Z","shell.execute_reply":"2024-07-16T06:53:45.982141Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nhelper to evaluate a single translation\n\"\"\"\n\ndef evaluate(encoder, decoder, sentence, input_lang, output_lang):\n    with torch.no_grad():\n        \n        input_ids = np.full((1, MAX_LENGTH_INPUT),  PADDING_token,  dtype=np.int32)\n        inputs = indexesFromSentence(input_lang, sentence)\n        inputs.append(EOS_token)\n        input_ids[0, : len(inputs)] = inputs\n        \n        input_tensor = torch.tensor(input_ids).to(device)\n\n        encoder_outputs, encoder_hidden = encoder(input_tensor)\n        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n\n        _, topi = decoder_outputs.topk(1)\n        decoded_ids = topi.squeeze()\n\n        decoded_words = []\n        for idx in decoded_ids:\n            if idx.item() == EOS_token:\n                decoded_words.append('<EOS>')\n                break\n            decoded_words.append(output_lang.index2word[idx.item()])\n    return decoded_words, decoder_attn","metadata":{"execution":{"iopub.status.busy":"2024-07-16T06:53:46.823959Z","iopub.execute_input":"2024-07-16T06:53:46.824334Z","iopub.status.idle":"2024-07-16T06:53:46.832200Z","shell.execute_reply.started":"2024-07-16T06:53:46.824305Z","shell.execute_reply":"2024-07-16T06:53:46.831269Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nget a taste of the translations\n\"\"\"\n\ndef evaluateRandomly(encoder, decoder, n=10):\n    for i in range(n):\n        pair = random.choice(pairs)\n        print('>', pair[0])\n        print('=', pair[1])\n        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n        output_sentence = ' '.join(output_words)\n        print('<', output_sentence)\n        print('')","metadata":{"id":"dic1NJ2rRfGX","execution":{"iopub.status.busy":"2024-07-16T06:53:47.920922Z","iopub.execute_input":"2024-07-16T06:53:47.921828Z","iopub.status.idle":"2024-07-16T06:53:47.927544Z","shell.execute_reply.started":"2024-07-16T06:53:47.921794Z","shell.execute_reply":"2024-07-16T06:53:47.926571Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"def print_key():\n    print(f\"KEY:\\n> INPUT\\n= TARGET\\n< MACHINE TRANSLATION\\n\\n----------------\\n\")\n\nencoder.eval()\ndecoder.eval()\n\nprint_key()\n# e, d = get_trained_models(\"encoder-trial-10\", \"decoder-trial-10\")\n# evaluateRandomly(e, d)\n# UNCOMMENT TO TEST WITH TRAINED MODEL DIRECTLY\nevaluateRandomly(encoder, decoder)","metadata":{"id":"cGxsoyXTWZSb","execution":{"iopub.status.busy":"2024-07-16T06:53:53.118985Z","iopub.execute_input":"2024-07-16T06:53:53.119379Z","iopub.status.idle":"2024-07-16T06:53:53.412656Z","shell.execute_reply.started":"2024-07-16T06:53:53.119350Z","shell.execute_reply":"2024-07-16T06:53:53.411719Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"KEY:\n> INPUT\n= TARGET\n< MACHINE TRANSLATION\n\n----------------\n\n> sequential ( \n   ( 0 ) : linear ( in_features = 1 ,  out_features = 8 ,  bias = true ) \n   ( 1 ) : linear ( in_features = 8 ,  out_features = 7 ,  bias = true ) \n )\n= this model has 2 layers . the input has shape [n ,  1] . the output has shape [n ,  7]\n< this model has 2 layers . the input has shape [n ,  1] . the output has shape [n ,  7] <EOS>\n\n> sequential ( \n   ( 0 ) : conv2d ( 8 ,  2 ,  kernel_size =  ( 2 ,  2 )  ,  stride =  ( 1 ,  1 )  ) \n   ( 1 ) : reshape (  ) \n   ( 2 ) : linear ( in_features = 7938 ,  out_features = 3 ,  bias = true ) \n )\n= this model has 3 layers . the input has shape [n ,  8 ,  h ,  w] . the output has shape [n ,  3]\n< this model has 3 layers . the input has shape [n ,  8 ,  h ,  w] . the output has shape [n ,  3] <EOS>\n\n> sequential ( \n   ( 0 ) : conv2d ( 6 ,  5 ,  kernel_size =  ( 4 ,  4 )  ,  stride =  ( 1 ,  1 )  ) \n )\n= this model has 1 layers . the input has shape [n ,  6 ,  h ,  w] . the output has shape [n ,  5 ,  h-4+1 ,  w-4+1]\n< this model has 1 layers . the input has shape [n ,  6 ,  h ,  w] . the output has shape [n ,  5 ,  h-4+1 ,  w-4+1] <EOS>\n\n> sequential ( \n   ( 0 ) : linear ( in_features = 3 ,  out_features = 2 ,  bias = true ) \n   ( 1 ) : reshape (  ) \n   ( 2 ) : conv2d ( 2 ,  2 ,  kernel_size =  ( 1 ,  1 )  ,  stride =  ( 1 ,  1 )  ) \n   ( 3 ) : reshape (  ) \n   ( 4 ) : linear ( in_features = 2 ,  out_features = 8 ,  bias = true ) \n   ( 5 ) : reshape (  ) \n   ( 6 ) : conv2d ( 2 ,  2 ,  kernel_size =  ( 1 ,  1 )  ,  stride =  ( 1 ,  1 )  ) \n )\n= this model has 7 layers . the input has shape [n ,  3] . the output has shape [n ,  2 ,  2 ,  2]\n< this model has 7 layers . the input has shape [n ,  3] . the output has shape [n ,  2 ,  2 ,  2] <EOS>\n\n> sequential ( \n   ( 0 ) : linear ( in_features = 4 ,  out_features = 9 ,  bias = true ) \n )\n= this model has 1 layers . the input has shape [n ,  4] . the output has shape [n ,  9]\n< this model has 1 layers . the input has shape [n ,  4] . the output has shape [n ,  9] <EOS>\n\n> sequential ( \n   ( 0 ) : conv2d ( 6 ,  9 ,  kernel_size =  ( 8 ,  8 )  ,  stride =  ( 1 ,  1 )  ) \n   ( 1 ) : reshape (  ) \n   ( 2 ) : linear ( in_features = 29241 ,  out_features = 3 ,  bias = true ) \n   ( 3 ) : reshape (  ) \n   ( 4 ) : conv2d ( 3 ,  3 ,  kernel_size =  ( 1 ,  1 )  ,  stride =  ( 1 ,  1 )  ) \n )\n= this model has 5 layers . the input has shape [n ,  6 ,  h ,  w] . the output has shape [n ,  3 ,  1 ,  1]\n< this model has 5 layers . the input has shape [n ,  6 ,  h ,  w] . the output has shape [n ,  3 ,  1 ,  1] <EOS>\n\n> sequential ( \n   ( 0 ) : linear ( in_features = 7 ,  out_features = 4 ,  bias = true ) \n   ( 1 ) : reshape (  ) \n   ( 2 ) : conv2d ( 1 ,  1 ,  kernel_size =  ( 1 ,  1 )  ,  stride =  ( 1 ,  1 )  ) \n   ( 3 ) : reshape (  ) \n   ( 4 ) : linear ( in_features = 4 ,  out_features = 7 ,  bias = true ) \n   ( 5 ) : linear ( in_features = 7 ,  out_features = 3 ,  bias = true ) \n )\n= this model has 6 layers . the input has shape [n ,  7] . the output has shape [n ,  3]\n< this model has 6 layers . the input has shape [n ,  7] . the output has shape [n ,  3] <EOS>\n\n> sequential ( \n   ( 0 ) : linear ( in_features = 8 ,  out_features = 2 ,  bias = true ) \n   ( 1 ) : linear ( in_features = 2 ,  out_features = 3 ,  bias = true ) \n   ( 2 ) : linear ( in_features = 3 ,  out_features = 1 ,  bias = true ) \n   ( 3 ) : reshape (  ) \n   ( 4 ) : conv2d ( 1 ,  1 ,  kernel_size =  ( 1 ,  1 )  ,  stride =  ( 1 ,  1 )  ) \n   ( 5 ) : reshape (  ) \n   ( 6 ) : linear ( in_features = 1 ,  out_features = 7 ,  bias = true ) \n )\n= this model has 7 layers . the input has shape [n ,  8] . the output has shape [n ,  7]\n< this model has 7 layers . the input has shape [n ,  8] . the output has shape [n ,  7] <EOS>\n\n> sequential ( \n   ( 0 ) : linear ( in_features = 4 ,  out_features = 3 ,  bias = true ) \n   ( 1 ) : linear ( in_features = 3 ,  out_features = 5 ,  bias = true ) \n   ( 2 ) : linear ( in_features = 5 ,  out_features = 1 ,  bias = true ) \n   ( 3 ) : linear ( in_features = 1 ,  out_features = 4 ,  bias = true ) \n   ( 4 ) : linear ( in_features = 4 ,  out_features = 6 ,  bias = true ) \n )\n= this model has 5 layers . the input has shape [n ,  4] . the output has shape [n ,  6]\n< this model has 5 layers . the input has shape [n ,  4] . the output has shape [n ,  6] <EOS>\n\n> sequential ( \n   ( 0 ) : conv2d ( 2 ,  2 ,  kernel_size =  ( 8 ,  8 )  ,  stride =  ( 1 ,  1 )  ) \n   ( 1 ) : reshape (  ) \n   ( 2 ) : linear ( in_features = 6498 ,  out_features = 9 ,  bias = true ) \n )\n= this model has 3 layers . the input has shape [n ,  2 ,  h ,  w] . the output has shape [n ,  9]\n< this model has 3 layers . the input has shape [n ,  2 ,  h ,  w] . the output has shape [n ,  9] <EOS>\n\n","output_type":"stream"}]},{"cell_type":"code","source":"\"\"\"\nhelper to get tensor translation of a single input. will be used to calculate metrics \n\"\"\"\n\ndef get_prediction(source, encoder, decoder, input_lang):\n    with torch.no_grad():\n        input_tensor = tensorFromSentence(input_lang, source)\n\n        encoder_outputs, encoder_hidden = encoder(input_tensor)\n        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n        \n        _, topi = decoder_outputs.topk(1)\n        decoded_ids = topi.squeeze(-1)\n    return decoded_ids\n\nsource, target = random.choice(pairs)\npredicted = get_prediction(source, encoder, decoder, input_lang)\nprint(f\"predicted : {predicted}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-16T06:54:00.886498Z","iopub.execute_input":"2024-07-16T06:54:00.887224Z","iopub.status.idle":"2024-07-16T06:54:00.925533Z","shell.execute_reply.started":"2024-07-16T06:54:00.887187Z","shell.execute_reply":"2024-07-16T06:54:00.924607Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"predicted : tensor([[ 2,  3,  4, 24,  6,  7,  8,  9,  4, 10, 11, 12, 13, 14, 12, 13, 15, 12,\n         13, 16,  7,  8, 17,  4, 10, 11, 12, 13, 31, 12, 13, 51, 12, 13, 52,  1,\n          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2]],\n       device='cuda:0')\n","output_type":"stream"}]},{"cell_type":"code","source":"\"\"\"\naccuracy metric definition\n\"\"\"\n\ndef create_ngrams(x , n):\n    return x.unfold(1,n,1)\n\ndef accuracy(predicted, target, ngram=1):\n    predicted_ngrams = create_ngrams(predicted, ngram)\n    target_ngrams = create_ngrams(target, ngram)\n    matches = (predicted_ngrams == target_ngrams).all(dim=2)\n    num = matches.sum()\n    denom = matches.numel()\n    #print(f\"matches : {num} , denom : {denom}\")\n    return num / denom","metadata":{"execution":{"iopub.status.busy":"2024-07-16T06:54:01.638660Z","iopub.execute_input":"2024-07-16T06:54:01.638995Z","iopub.status.idle":"2024-07-16T06:54:01.644859Z","shell.execute_reply.started":"2024-07-16T06:54:01.638967Z","shell.execute_reply":"2024-07-16T06:54:01.644001Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"\"\"\"\ngeneric metric calculator. f is the metric function\n\"\"\"\ndef metric(f, encoder, decoder):\n    pair = random.choice(pairs)\n    target_ids = np.full((1, MAX_LENGTH_OUTPUT),  PADDING_token,  dtype=np.int32)\n    target = indexesFromSentence(output_lang, pair[1])\n    target.append(EOS_token)\n    target_ids[0, : len(target)] = target\n    \n    predicted = get_prediction(pair[0], encoder, decoder, input_lang)\n    \n    return f(predicted, torch.tensor(target_ids).to(device))\n\nx = metric(accuracy, encoder, decoder)\nprint(f\"metric for a single random item {x.item()}/1.0\")","metadata":{"execution":{"iopub.status.busy":"2024-07-16T06:54:02.368960Z","iopub.execute_input":"2024-07-16T06:54:02.369578Z","iopub.status.idle":"2024-07-16T06:54:02.417461Z","shell.execute_reply.started":"2024-07-16T06:54:02.369547Z","shell.execute_reply":"2024-07-16T06:54:02.416531Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"metric for a single random item 0.3799999952316284/1.0\n","output_type":"stream"}]},{"cell_type":"code","source":"\"\"\"\nactual metric calculation with a stroed model\n\"\"\"\n\ndef metric(f, encoder, decoder):\n    acc = 0.0\n    num = 0 \n    for data in test_loader:\n        input_tensor, target_tensor = data\n        batch_size = input_tensor.size(0)\n        encoder_outputs, encoder_hidden = encoder(input_tensor)\n        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden)\n        decoder_outputs = ((decoder_outputs.topk(1)[1]).squeeze(-1))\n        t_acc = f(decoder_outputs, target_tensor)\n        acc = ( (t_acc * batch_size) + (acc * num) ) / (num + batch_size)\n        num = num + batch_size\n    return acc\n        \ne, d = get_trained_models(\"encoder-trial-10\", \"decoder-trial-10\")\n\nm = metric(accuracy, e, d)\nprint(f\"Accuracy metric: {m.item()/1.0}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-16T06:54:05.542035Z","iopub.execute_input":"2024-07-16T06:54:05.542948Z","iopub.status.idle":"2024-07-16T06:54:10.009081Z","shell.execute_reply.started":"2024-07-16T06:54:05.542916Z","shell.execute_reply":"2024-07-16T06:54:10.008136Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"Accuracy metric: 0.9999993443489075\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**This completes my implementation. I will list some improvements that I am thinking of here for completeness:**\n\n1. I can include more type of layers. Right now I am using Linear and Conv2d layers. It will be easy to add ReLU and MaxPool layers. I'll have to spend some time for adding other types of layers if I wish to maintain \"shape compatibility\" between layers.\n\n2. I am just using Sequential layers right now. I could use generic Module derived classes. Again, that will be work in the synthetic data generation segment\n\n3. Can increase num layers in the models. Right now it's upto 6 layers. This will increase MAX_LENGTH for input so I'll have to see how the RNN handles that.\n\n4. Can add more metrics based on precision and recall. (something similar to BLEU or ROGUE). May also think about \"PADDING\" matches to have a lower weight for metric calculations","metadata":{}},{"cell_type":"code","source":"\"\"\"\nOLD SIMPLE IMPLEMENTATION OF SYNTHETIC DATA GENERATION. NOT USED NOW.\n\"\"\"\n\n\n\"\"\"\nsimple_synthetic_data_generator generates a single synthetic input\n\nfor simplicity, I have used only Linear and Conv1d layers as part of my Input.\n\"\"\"\n\ndef get_shape_helper(model, stage):\n  if isinstance(model, nn.Linear):\n    if stage == \"input\":\n      return f\"(b, {model.in_features})\"\n    elif stage == \"output\":\n      return f\"(b, {model.out_features})\"\n  if isinstance(model, nn.Conv1d):\n    if stage == \"input\":\n      return f\"(b, {model.in_channels}, l)\"\n    elif stage == \"output\":\n      return f\"(b, {model.out_channels}, l)\"\n  return NotImplementedError()\n\n\ndef simple_synthetic_data_generator(model):\n  children = list(model.named_children())\n  desc = f\"this model has {len(children)} layers.\"\n  if(len(children) > 0):\n    desc = desc + f\" the input has shape {get_shape_helper(children[0][1], 'input')} and the output has shape {get_shape_helper(children[-1][1], 'output')}\"\n  return desc\n\n\"\"\"\ntest to see input for non empty model\n\"\"\"\n\ndef non_empty_model_test():\n  non_empty_model = nn.Sequential(nn.Linear(12,30), nn.Linear(30,1))\n  print(simple_synthetic_data_generator(non_empty_model))\nnon_empty_model_test()\n\n\n\"\"\"\ntest to see input for empty model\n\"\"\"\n\ndef empty_model_test():\n  empty_model = nn.Sequential()\n  print(simple_synthetic_data_generator(empty_model))\nempty_model_test()\n\n\"\"\"\nAssume that each layer has 0-9 input and output number of nodes / kernels etc.\n\"\"\"\n\ndef get_random_sizes_for_layers(dims):\n  return np.random.randint(0, 10, dims)\n\n\"\"\"\nCreate a synthetic dataset.\n\nThe random selection of layers here means that the created synthetic model may throw runtime errors. \nHowever, that is not a problem for the task at hand. In fact, the random selection of layers and dims in the synthetic \ndataset means our trained seq2seq model learns a harder task as there is less \"structure\" in our synthetic models. \n\"\"\"\n\nNUM_ITEMS = 20000\n\ndef create_dataset_old(num_items):\n  layer_options = [(nn.Linear, 2), (nn.Conv1d, 3)] # use linear and conv1d layers\n  len_layer_optins = len(layer_options)\n  data_pairs = []\n  for item in range(num_items):\n    num_layers = np.random.randint(0,6) # assume 0-2 layers only\n    layers = []\n    for _ in range(num_layers):\n      layer_tuple = layer_options[np.random.randint(0,len(layer_options))] # pick layer type\n      layer = layer_tuple[0]\n      dims = layer_tuple[1]\n      layers.append(layer(*get_random_sizes_for_layers(dims))) # add layer to architecture\n    model = nn.Sequential(*layers)\n    data_pairs.append({\"model\": model.__str__(), \"desc\": simple_synthetic_data_generator(model)})\n  return data_pairs\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MZzwSopcjiNy","outputId":"cf649614-d576-4062-fcd9-c81e37c0707b","execution":{"iopub.status.busy":"2024-07-16T06:23:20.369049Z","iopub.status.idle":"2024-07-16T06:23:20.369550Z","shell.execute_reply.started":"2024-07-16T06:23:20.369293Z","shell.execute_reply":"2024-07-16T06:23:20.369313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}